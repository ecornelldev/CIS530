{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e5835542f6f95e1f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h2>About this Project</h2>\n",
    "<p>In this project you will implement k-NN to classify images of faces. You will use the NumPy library to implement functions that will find nearest neighbors, calculate absolute loss, perform k-NN classification on a data set, and calculate the accuracy of your classifier.</p>\n",
    "\n",
    "\n",
    "<h3>Evaluation</h3>\n",
    "\n",
    "<p><strong>This project must be successfully completed and submitted in order to receive credit for this course. Your score on this project will be included in your final grade calculation.</strong></p>\n",
    "    \n",
    "<p>You are expected to write code where you see <em># YOUR CODE HERE</em> within the cells of this notebook. Not all cells will be graded; code input cells followed by cells marked with <em>#Autograder test cell</em> will be graded. Upon submitting your work, the code you write at these designated positions will be assessed using an \"autograder\" that will run all test cells to assess your code. You will receive feedback from the autograder that will identify any errors in your code. Use this feedback to improve your code if you need to resubmit. Be sure not to change the names of any provided functions, classes, or variables within the existing code cells, as this will interfere with the autograder. Also, remember to execute all code cells sequentially, not just those you’ve edited, to ensure your code runs properly.</p>\n",
    "    \n",
    "<p>You can resubmit your work as many times as necessary before the submission deadline. If you experience difficulty or have questions about this exercise, use the Q&A discussion board to engage with your peers or seek assistance from the instructor.</p>\n",
    "\n",
    "<p>Before starting your work, please review <a href=\"https://s3.amazonaws.com/ecornell/global/eCornellPlagiarismPolicy.pdf\">eCornell's policy regarding plagiarism</a> (the presentation of someone else's work as your own without source credit).</p>\n",
    "\n",
    "<h3>Submit Code for Autograder Feedback</h3>\n",
    "\n",
    "<p>Once you have completed your work on this notebook, you will submit your code for autograder review. Follow these steps:</p>\n",
    "\n",
    "<ol>\n",
    "  <li><strong>Save your notebook.</strong></li>\n",
    "  <li><strong>Mark as Completed —</strong> In the blue menu bar along the top of this code exercise window, you’ll see a menu item called <strong>Education</strong>. In the <strong>Education</strong> menu, click <strong>Mark as Completed</strong> to submit your code for autograder/instructor review. This process will take a moment and a progress bar will show you the status of your submission.</li>\n",
    "\t<li><strong>Review your results —</strong> Once your work is marked as complete, the results of the autograder will automatically be presented in a new tab within the code exercise window. You can click on the assessment name in this feedback window to see more details regarding specific feedback/errors in your code submission.</li>\n",
    "  <li><strong>Repeat, if necessary —</strong> The Jupyter notebook will always remain accessible in the first tabbed window of the exercise. To reattempt the work, you will first need to click <strong>Mark as Uncompleted</strong> in the <strong>Education</strong> menu and then proceed to make edits to the notebook. Once you are ready to resubmit, follow steps one through three. You can repeat this procedure as many times as necessary.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3e747cf31a39895c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h2>Import Libraries</h2>\n",
    "\n",
    "<p>Before you get started, you need to import a few libraries. You can do this by executing the following code. Remember, run code in a cell by selecting the cell, holding the shift key, and pressing enter/return.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c5f7e10c9b80a142",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import sys\n",
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "from helper import runtest, l2distance, findknn_grader, loaddata, visualize_knn_2D, visualize_knn_images, plotfaces, visualize_knn_boundary\n",
    "\n",
    "\n",
    "print('You\\'re running python %s' % sys.version.split(' ')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e3889b4538ffaef1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h2>k-Nearest Neighbors Implementation in Python</h2>\n",
    "\n",
    "<p>The goal of implementing your $k$-NN classifier is to build a classifier for face recognition. We have obtained some data, images of faces, for testing your code. The data resides in the file <code>faces.mat</code>, which holds the dataset for our exercises below.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a188cc90811f7b23",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<p>We will refer to the training vectors as <b>xTr</b> with labels <b>yTr</b>. Our testing vectors are <b>xTe</b> with labels <b>yTe</b>.\n",
    "As a reminder, to predict the label or class of an image in <b>xTe</b>, we will look for the <i>k</i>-nearest neighbors in <b>xTr</b> and predict a label based on their labels in <b>yTr</b>. For evaluation, we will compare these labels against the true labels provided in <b>yTe</b>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cd644da84e9643c9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3> Visualizing the Data</h3>\n",
    "\n",
    "<p>Let us take a look at the data. The following script will take the first ten training images from the face dataset and visualize them. Run the code cell to see the visualized data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-464aed1fe6c60140",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "xTr,yTr,xTe,yTe=loaddata(\"faces.mat\")\n",
    "\n",
    "plt.figure(figsize=(11,8))\n",
    "plotfaces(xTr[:9, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bfa7bd73ad3567fb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "<h2>Implement k-NN for Facial Recognition</h2>\n",
    "<p>The following four project parts will step you through implementing each function necessary to build your facial recognition system.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a7aef585a0780e8d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3>Part 1: Implement <b><code>findknn</code></b> [Graded]</h3>\n",
    "\n",
    "<p>Implement the function <b><code>findknn</code></b>, which should find the $k$ nearest neighbors of a set of vectors within a given training data set. The call of:</p>\n",
    "<pre>\n",
    " [I,D]=findknn(xTr,xTe,k);\n",
    "</pre> \n",
    "<p>should result in two matrices $I$ and $D$, both of dimensions $k\\times n$, where $n$ is the number of input vectors in <code>xTe</code>. The matrix $I(i,j)$ is the index of the $i^{th}$ nearest neighbor of the vector $xTe(j,:)$.</p>\n",
    "<p>\n",
    "So, for example, if we set <code>i=I(1,3)</code>, then <code>xTr(i,:)</code> is the first nearest neighbor of vector <code>xTe(3,:)</code>. The second matrix $D$ returns the corresponding distances. So $D(i,j)$ is the distance of $xTe(j,:)$ to its $i^{th}$ nearest neighbor.</p>\n",
    "<p>You will use <code>np.argsort()</code> and <code>np.sort()</code> in the implementation of this function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-findknn",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def findknn(xTr,xTe,k):\n",
    "    \"\"\"\n",
    "    function [indices,dists]=findknn(xTr,xTe,k);\n",
    "    \n",
    "    Finds the k nearest neighbors of xTe in xTr.\n",
    "    \n",
    "    Input:\n",
    "    xTr = nxd input matrix with n row-vectors of dimensionality d\n",
    "    xTe = mxd input matrix with m row-vectors of dimensionality d\n",
    "    k = number of nearest neighbors to be found\n",
    "    \n",
    "    Output:\n",
    "    indices = kxm matrix, where indices(i,j) is the i^th nearest neighbor of xTe(j,:)\n",
    "    dists = Euclidean distances to the respective nearest neighbors\n",
    "    \"\"\"\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    D = l2distance(xTr, xTe)\n",
    "    indices = np.argsort(D, axis=0)\n",
    "    dists = np.sort(D, axis=0)\n",
    "    return indices[:k,:], dists[:k,:]\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-findknn_selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Run this self-test cell to check your code\n",
    "\n",
    "def knn_1():\n",
    "    xTr = np.random.rand(500,100)\n",
    "    xTe = np.random.rand(100,100)\n",
    "    Ig,Dg = findknn_grader(xTr,xTe,1)\n",
    "    Is,Ds = findknn(xTr,xTe,1)\n",
    "    test = np.linalg.norm(Ig - Is) + np.linalg.norm(Dg - Ds)\n",
    "    return test<1e-5 \n",
    "\n",
    "def knn_3():\n",
    "    xTr = np.random.rand(500,100)\n",
    "    xTe = np.random.rand(100,100)\n",
    "    Ig,Dg = findknn_grader(xTr,xTe,3)\n",
    "    Is,Ds = findknn(xTr,xTe,3)\n",
    "    test = np.linalg.norm(Ig - Is) + np.linalg.norm(Dg - Ds)\n",
    "    return test<1e-5\n",
    "\n",
    "runtest(knn_1,'knn_1')\n",
    "runtest(knn_3,'knn_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-knn_1_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_1\n",
    "### BEGIN HIDDEN TESTS\n",
    "xTr = np.random.rand(500,100)\n",
    "xTe = np.random.rand(100,100)\n",
    "Ig,Dg = findknn_grader(xTr,xTe,1)\n",
    "Is,Ds = findknn(xTr,xTe,1)\n",
    "test = np.linalg.norm(Ig - Is) + np.linalg.norm(Dg - Ds)\n",
    "assert test<1e-5 \n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-knn_3_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_3\n",
    "### BEGIN HIDDEN TESTS\n",
    "xTr = np.random.rand(500,100)\n",
    "xTe = np.random.rand(100,100)\n",
    "Ig,Dg = findknn_grader(xTr,xTe,3)\n",
    "Is,Ds = findknn(xTr,xTe,3)\n",
    "test = np.linalg.norm(Ig - Is) + np.linalg.norm(Dg - Ds)\n",
    "assert test<1e-5\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-da16c742b63ecb6e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<p>The following demo samples random points in 2D. If your <code>findknn</code> function is correctly implemented, you should be able to click anywhere on the plot to add a test point. The function should then draw direct connections from your test point to the k  nearest neighbors. Verify manually if your code is correct.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-602dbde808c73078",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "visualize_knn_2D(findknn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f271ff7465410f92",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<p>We can visualize the k=3 nearest training neighbors of some of the test points (Click on the image to cycle through different test points).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e5142d1f3cab1ce7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "visualize_knn_images(findknn, imageType='faces')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b8955aefe424fd31",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3>Part 2: Implement <b><code>analyze</code></b> [Graded]</h3>\n",
    "\n",
    "<p>The function <b><code>analyze</code></b> should compute various metrics to evaluate a classifier. The call of:</p>\n",
    "<pre>\n",
    "  result=analyze(kind,truth,preds);\n",
    "</pre>\n",
    "<p>should output the <b>accuracy</b> or <b>absolute loss</b> in variable <code>result</code>. The type of output required can be specified in the input argument <code>kind</code> as <code>\"abs\"</code> or <code>\"acc\"</code>. The input variables <code>truth</code> and <code>pred</code> should contain vectors of true and predicted labels respectively.</p>\n",
    "<p>For example, the call:</p>\n",
    "<pre>\n",
    ">> analyze('acc',[1 2 1 2],[1 2 1 1])\n",
    "</pre>\n",
    "<p>should return an accuracy of 0.75. Here, the true labels are 1,2,1,2 and the predicted labels are 1,2,1,1. So the first three examples are classified correctly, and the last one is wrong --- 75% accuracy.</p>\n",
    "<p>You will need to use the following functions: <code>flatten()</code>, <code>np.sum()</code> and <code>np.abs()</code>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-analyze",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def analyze(kind,truth,preds):\n",
    "    \"\"\"\n",
    "    function output=analyze(kind,truth,preds)         \n",
    "    Analyzes the accuracy of a prediction\n",
    "    Input:\n",
    "    kind='acc' classification accuracy\n",
    "    kind='abs' absolute loss\n",
    "    (other values of 'kind' will follow later)\n",
    "    \"\"\"\n",
    "    \n",
    "    truth = truth.flatten()\n",
    "    preds = preds.flatten()\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    if len(truth) == 0 and len(preds) == 0:\n",
    "        output = 0\n",
    "        return output\n",
    "    if kind == 'abs':\n",
    "        # compute the absolute difference between truth and predictions\n",
    "        output = np.sum(np.abs(truth - preds)) / float(len(truth))\n",
    "    elif kind == 'acc':\n",
    "        output = np.sum(truth == preds) / float(len(truth))\n",
    "    return output\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-analyze_selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Run this self-test cell to check your code\n",
    "\n",
    "def analyze_acc():\n",
    "    truth = np.array([1, 2, 3, 4])\n",
    "    preds = np.array([1, 2, 3, 0])\n",
    "    return abs(analyze('acc',truth,preds) - 0.75)<1e-10\n",
    "\n",
    "def analyze_abs():\n",
    "    truth = np.array([0.5, 1, 3, 4])\n",
    "    preds = np.array([1, 2, 3, 0])\n",
    "    return abs(analyze('abs',truth,preds) - 1.375)<1e-10\n",
    "\n",
    "runtest(analyze_acc,'analyze_acc')\n",
    "runtest(analyze_abs,'analyze_abs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-analyze_acc_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs analyze_acc\n",
    "### BEGIN HIDDEN TESTS\n",
    "truth = np.array([1, 2, 3, 4])\n",
    "preds = np.array([1, 2, 3, 0])\n",
    "assert abs(analyze('acc',truth,preds) - 0.75)<1e-10\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-analyze_abs_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs analyze_abs\n",
    "### BEGIN HIDDEN TESTS\n",
    "truth = np.array([0.5, 1, 3, 4])\n",
    "preds = np.array([1, 2, 3, 0])\n",
    "assert abs(analyze('abs',truth,preds) - 1.375)<1e-10\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fcd1c8e4a92e349e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3>Part 3: Implement <b><code>knnclassifier</code></b> [Graded]</h3>\n",
    "\n",
    "<p>Implement the function <b><code>knnclassifier</code></b>, which should perform $k$ nearest neighbor classification on a given test data set. The call:</p>\n",
    "<pre>preds=knnclassifier(xTr,yTr,xTe,k)</pre>\n",
    "<p>should output the predictions for the data in <code>xTe</code> i.e. <code>preds[i]</code> will contain the prediction for <code>xTe[i,:]</code>.</p>\n",
    "\n",
    "<p>You will need to use <code>flatten()</code> in the implementation of this function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-knnclassifier",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def knnclassifier(xTr,yTr,xTe,k):\n",
    "    \"\"\"\n",
    "    function preds=knnclassifier(xTr,yTr,xTe,k);\n",
    "    \n",
    "    k-nn classifier \n",
    "    \n",
    "    Input:\n",
    "    xTr = nxd input matrix with n row-vectors of dimensionality d\n",
    "    xTe = mxd input matrix with m row-vectors of dimensionality d\n",
    "    k = number of nearest neighbors to be found\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    preds = predicted labels, ie preds(i) is the predicted label of xTe(i,:)\n",
    "    \"\"\"\n",
    "    # fix array shapes\n",
    "    yTr = yTr.flatten()\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    inds, _ = findknn_grader(xTr, xTe, k)\n",
    "    m, d = xTe.shape\n",
    "    vs = yTr[inds]\n",
    "    preds = np.array([mode(vs[:,i])[0] for i in range(m)]).flatten()\n",
    "    return preds\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-knnclassifier_selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Run this self-test cell to check your code\n",
    "\n",
    "def knn_classifier_test1():\n",
    "    X = np.array([[1,0,0,1],[0,1,0,1]]).T\n",
    "    y = np.array([1,1,2,2])\n",
    "    np.testing.assert_allclose(knnclassifier(X,y,X,1),y)\n",
    "    return np.testing.assert_allclose\n",
    "\n",
    "def knn_classifier_test2():\n",
    "    X = np.array([[1,0,0,1],[0,1,0,1]]).T\n",
    "    y = np.array([1,1,2,2])\n",
    "    y2 = np.array([2,2,1,1])\n",
    "    return np.array_equal(knnclassifier(X,y,X,3),y2)\n",
    "\n",
    "def knn_classifier_test3():\n",
    "    X = np.array([[-4,-3,-2,2,3,4]]).T\n",
    "    y = np.array([1,1,1,2,2,2])\n",
    "    X2 = np.array([[-1,1]]).T\n",
    "    y2 = np.array([1,2])\n",
    "    return np.array_equal(knnclassifier(X,y,X2,2),y2)\n",
    "\n",
    "def knn_classifier_test4():\n",
    "    X = np.array([[-4,-3,-2,2,3,4]]).T\n",
    "    y = np.array([1,1,1,2,2,2])\n",
    "    X2 = np.array([[0,1]]).T\n",
    "    y2 = np.array([1,2])\n",
    "    y3 = np.array([2,2])\n",
    "    return np.array_equal(knnclassifier(X,y,X2,2),y2) or np.array_equal(knnclassifier(X,y,X2,2),y3)\n",
    "\n",
    "def knn_classifier_test5():\n",
    "    X = np.random.rand(4,4)\n",
    "    y = np.array([1,2,2,2])\n",
    "    return analyze('acc',knnclassifier(X,y,X,1),y) == 1\n",
    "\n",
    "def knn_classifier_test6():\n",
    "    X = np.random.rand(4,4)\n",
    "    y = np.array([1,2,1,2])\n",
    "    return analyze('abs',knnclassifier(X,y,X,1),y) == 0\n",
    "\n",
    "def knn_classifier_test7():\n",
    "    X = np.random.rand(10,100)\n",
    "    y = np.round(np.random.rand(10)).astype('int')\n",
    "    return analyze('acc',knnclassifier(X,y,X,1),y) == 1\n",
    "\n",
    "runtest(knn_classifier_test1,'knn_classifier_test1')\n",
    "runtest(knn_classifier_test2,'knn_classifier_test2')\n",
    "runtest(knn_classifier_test3,'knn_classifier_test3')\n",
    "runtest(knn_classifier_test4,'knn_classifier_test4')\n",
    "runtest(knn_classifier_test5,'knn_classifier_test5')\n",
    "runtest(knn_classifier_test6,'knn_classifier_test6')\n",
    "runtest(knn_classifier_test7,'knn_classifier_test7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "knn_classifier_test1",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_classifier_test1\n",
    "### BEGIN HIDDEN TESTS\n",
    "X = np.array([[1,0,0,1],[0,1,0,1]]).T\n",
    "y = np.array([1,1,2,2])\n",
    "np.testing.assert_allclose(knnclassifier(X,y,X,1),y)\n",
    "assert np.testing.assert_allclose\n",
    "### END HIDDEN TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "knn_classifier_test2",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_classifier_test2\n",
    "### BEGIN HIDDEN TESTS\n",
    "X = np.array([[1,0,0,1],[0,1,0,1]]).T\n",
    "y = np.array([1,1,2,2])\n",
    "y2 = np.array([2,2,1,1])\n",
    "assert np.array_equal(knnclassifier(X,y,X,3),y2)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "knn_classifier_test3",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_classifier_test3\n",
    "### BEGIN HIDDEN TESTS\n",
    "X = np.array([[-4,-3,-2,2,3,4]]).T\n",
    "y = np.array([1,1,1,2,2,2])\n",
    "X2 = np.array([[-1,1]]).T\n",
    "y2 = np.array([1,2])\n",
    "assert np.array_equal(knnclassifier(X,y,X2,2),y2)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "knn_classifier_test4",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_classifier_test4\n",
    "### BEGIN HIDDEN TESTS\n",
    "X = np.array([[-4,-3,-2,2,3,4]]).T\n",
    "y = np.array([1,1,1,2,2,2])\n",
    "X2 = np.array([[0,1]]).T\n",
    "y2 = np.array([1,2])\n",
    "y3 = np.array([2,2])\n",
    "assert np.array_equal(knnclassifier(X,y,X2,2),y2) or np.array_equal(knnclassifier(X,y,X2,2),y3)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "knn_classifier_test5",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_classifier_test5\n",
    "### BEGIN HIDDEN TESTS\n",
    "X = np.random.rand(4,4)\n",
    "y = np.array([1,2,2,2])\n",
    "assert analyze('acc',knnclassifier(X,y,X,1),y) == 1\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "knn_classifier_test6",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_classifier_test6\n",
    "### BEGIN HIDDEN TESTS\n",
    "X = np.random.rand(4,4)\n",
    "y = np.array([1,2,1,2])\n",
    "assert analyze('abs',knnclassifier(X,y,X,1),y) == 0\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "knn_classifier_test7",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_classifier_test7\n",
    "### BEGIN HIDDEN TESTS\n",
    "X = np.random.rand(10,100)\n",
    "y = np.round(np.random.rand(10)).astype('int')\n",
    "assert analyze('acc',knnclassifier(X,y,X,1),y) == 1\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e55bd469b83ac3e4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<p>You can compute the actual classification error on the test set by calling</p>\n",
    "<pre>\n",
    ">> analyze(\"acc\",yTe,knnclassifier(xTr,yTr,xTe,3))\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5239c4444c1d6114",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3><b>Part 4: Calculate Accuracy</b></h3>\n",
    "\n",
    "<p>The following script runs your $k$-nearest neighbor classifier over the faces and digits data set. The faces data set has $40$ classes and the digits data set has $10$. What classification accuracy would you expect from a random classifier?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-922378fd6fbb2a87",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Face Recognition: (1-nn)\")\n",
    "xTr,yTr,xTe,yTe=loaddata(\"faces.mat\") # load the data\n",
    "t0 = time.time()\n",
    "preds = knnclassifier(xTr,yTr,xTe,1)\n",
    "result=analyze(\"acc\",yTe,preds)\n",
    "t1 = time.time()\n",
    "print(\"You obtained %.2f%% classification acccuracy in %.4f seconds\\n\" % (result*100.0,t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eb6a7d56ba0d4525",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3>k-NN Boundary Visualization</h3>\n",
    "\n",
    "<p>To help give you a visual understanding of how the k-NN boundary is affected by $k$ and the specific dataset, feel free to play around with the visualization below. Click anywhere in the graph to add a negative class point. Hold down 'p' and click anywhere to add a positive class point. To increase $k$ hold down 'h' and click anywhere.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-008b8e19515ab42b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "visualize_knn_boundary(knnclassifier)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
