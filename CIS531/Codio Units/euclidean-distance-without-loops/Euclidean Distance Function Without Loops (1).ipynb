{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b707a0f33997e5a6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h2>About this Exercise</h2>\n",
    "<p>In the preceding activity, you derived a Euclidean distance matrix. Now that you have calculated the distance between points in terms of matrix operations, you are ready to write an efficient program that leverages NumPy's optimized functions. In this code exercise, rather than using loops, you will write a function to compute Euclidean distances between sets of vectors using NumPy functions.</p>\n",
    "\n",
    "<h3>Evaluation</h3>\n",
    "\n",
    "<p><strong>You must complete this exercise in order to unlock the final project in this module. Your score on this assignment will not be included in the final grade calculation.</strong><p>\n",
    "\n",
    "<p>You are expected to write code where you see <em># YOUR CODE HERE</em> within the cells of this notebook. Not all cells will be graded; code input cells followed by cells marked with <em>#Autograder test cell</em> will be graded. Upon submitting your work, the code you write at these designated positions will be assessed using an \"autograder\" that will run all test cells to assess your code. You will receive feedback from the autograder that will identify any errors in your code. Use this feedback to improve your code if you need to resubmit. Be sure not to change the names of any provided functions, classes, or variables within the existing code cells, as this will interfere with the autograder. Also, remember to execute all code cells sequentially, not just those you’ve edited, to ensure your code runs properly.</p>\n",
    "    \n",
    "<p>You can resubmit your work as many times as necessary before the submission deadline. If you experience difficulty or have questions about this exercise, use the Q&A discussion board to engage with your peers or seek assistance from the instructor.<p>\n",
    "\n",
    "<p>Before starting your work, please review <a href=\"https://s3.amazonaws.com/ecornell/global/eCornellPlagiarismPolicy.pdf\">eCornell's policy regarding plagiarism</a> (the presentation of someone else's work as your own without source credit).</p>\n",
    "\n",
    "<h3>Submit Code for Autograder Feedback</h3>\n",
    "\n",
    "<p>Once you have completed your work on this notebook, you will submit your code for autograder review. Follow these steps:</p>\n",
    "\n",
    "<ol>\n",
    "  <li><strong>Save your notebook.</strong></li>\n",
    "  <li><strong>Mark as Completed —</strong> In the blue menu bar along the top of this code exercise window, you’ll see a menu item called <strong>Education</strong>. In the <strong>Education</strong> menu, click <strong>Mark as Completed</strong> to submit your code for autograder/instructor review. This process will take a moment and a progress bar will show you the status of your submission.</li>\n",
    "\t<li><strong>Review your results —</strong> Once your work is marked as complete, the results of the autograder will automatically be presented in a new tab within the code exercise window. You can click on the assessment name in this feedback window to see more details regarding specific feedback/errors in your code submission.</li>\n",
    "  <li><strong>Repeat, if necessary —</strong> The Jupyter notebook will always remain accessible in the first tabbed window of the exercise. To reattempt the work, you will first need to click <strong>Mark as Uncompleted</strong> in the <strong>Education</strong> menu and then proceed to make edits to the notebook. Once you are ready to resubmit, follow steps one through three. You can repeat this procedure as many times as necessary.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-484d568322c19544",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h2>Import NumPy and Check Python Version</h2>\n",
    "\n",
    "First, you must import NumPy. Let's also check our version of Python. We've added the code for you for this first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-855640210fb50121",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running python 3.6.7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np # Numpy is Python's built in library for matrix operations.\n",
    "from pylab import * \n",
    "sys.path.append('/home/codio/workspace/.guides/hf')\n",
    "from helper import *\n",
    "print('You\\'re running python %s' % sys.version.split(' ')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-76ba5d8756566b5b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "<h2> Euclidean Distances in Python </h2>\n",
    "\n",
    "<p>Many machine learning algorithms access their input data primarily through pairwise (Euclidean) distances, therefore it is important that we have a fast function that computes pairwise distances of input vectors.</p>\n",
    "<p>Assume we have $n$ data vectors $\\mathbf{x_1},\\dots,\\mathbf{x_n}\\in{\\cal R}^d$ and $m$ vectors $\\mathbf{z_1},\\dots,z_m\\in{\\cal R}^d$. With these data vectors, let us define two matrices $X=[\\mathbf{x_1},\\dots,\\mathbf{x_n}]\\in{\\cal R}^{n\\times d}$, where the $i^{th}$ row is a vector $\\mathbf{x_i}$ and similarly $Z=[\\mathbf{z_1},\\dots,\\mathbf{z_m}]\\in{\\cal R}^{m\\times d}$. </p>\n",
    "<p>We want a distance function that takes as input these two matrices $X$ and $Z$ and outputs a matrix $D\\in{\\cal R}^{n\\times m}$, where \n",
    "\t$$D_{ij}=\\sqrt{(\\mathbf{x_i}-\\mathbf{z_j})(\\mathbf{x_i}-\\mathbf{z_j})^\\top}.$$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-80d59217b0d669d1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "A naïve implementation to compute pairwise distances may look like the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3724f30031f0f96e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def l2distanceSlow(X,Z=None):\n",
    "    if Z is None:\n",
    "        Z = X\n",
    "    \n",
    "    n, d = X.shape     # dimension of X\n",
    "    m= Z.shape[0]   # dimension of Z\n",
    "    D=np.zeros((n,m)) # allocate memory for the output matrix\n",
    "    for i in range(n):     # loop over vectors in X\n",
    "        for j in range(m): # loop over vectors in Z\n",
    "            D[i,j]=0.0; \n",
    "            for k in range(d): # loop over dimensions\n",
    "                D[i,j]=D[i,j]+(X[i,k]-Z[j,k])**2; # compute l2-distance between the ith and jth vector\n",
    "            D[i,j]=np.sqrt(D[i,j]); # take square root\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-768d33132116bada",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Please read through the code above carefully and make sure you understand it. It is perfectly correct and will produce the correct result... eventually. To see what is wrong, try running the <code>l2distanceSlow</code> code below on an extremely small matrix <code>X</code>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1afe58e13cd02172",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X=np.random.rand(700,100)\n",
    "print(\"Running the naive version for the...\")\n",
    "%time Dslow=l2distanceSlow(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-60d671b817b29b1c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "This code defines some random data in $X$ and computes the corresponding distance matrix $D$. The <em>%time</em> statement determines how long this code takes to run. This implementation is much too slow for such a simple operation on a small amount of data, and writing code like this to deal with matrices in this course will result in code that takes <strong>days</strong> to run.\n",
    "\n",
    "<strong>As a general rule, you should avoid tight loops at all cost.</strong> As you will see in the remainder of this exercise, you can do much better by performing bulk matrix operations using the NumPy package, which calls highly optimized compiled code behind the scenes.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4b648ecf382bce9f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h2> Efficient Programming with NumPy </h2>\n",
    "\n",
    "<p>Although there is an execution overhead per line in Python, matrix operations are optimized and fast. In order to successfully program in this course, you need to free yourself from \"for-loop\" thinking and start thinking in terms of matrix operations. Python for scientific computing can be very fast if almost all the time is spent on a few heavy duty matrix operations. In this exercise, you will transform the function above into a few matrix operations <em>without any loops at all.</em> </p> \n",
    "\n",
    "<p>The key to efficient programming in Python for machine learning in general is to think about it in terms of mathematics and not in terms of loops. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ccba76afed0964c4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h2>Exercises</h2>\n",
    "\n",
    "<p>In the following three exercises, you'll take the steps necessary to implement the euclidean distance function without loops.</p>\n",
    "\n",
    "<h3>Exercise 1: Inner-Product Matrix</h3>\n",
    "\n",
    "<p>Show that the Inner-Product Matrix (Gram matrix) can be expressed in terms of pure matrix multiplication.\n",
    "\n",
    "$$\tG_{ij}=\\mathbf{x}_i\\mathbf{z}_j^\\top $$\n",
    "\n",
    "Once you are done with the derivation, implement the function <strong><code>innerproduct</code></strong>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-Innerproduct",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def innerproduct(X,Z=None):\n",
    "    # function innerproduct(X,Z)\n",
    "    #\n",
    "    # Computes the inner-product matrix.\n",
    "    # Syntax:\n",
    "    # D=innerproduct(X,Z)\n",
    "    # Input:\n",
    "    # X: nxd data matrix with n vectors (rows) of dimensionality d\n",
    "    # Z: mxd data matrix with m vectors (rows) of dimensionality d\n",
    "    #\n",
    "    # Output:\n",
    "    # Matrix G of size nxm\n",
    "    # G[i,j] is the inner-product between vectors X[i,:] and Z[j,:]\n",
    "    #\n",
    "    # call with only one input:\n",
    "    # innerproduct(X)=innerproduct(X,X)\n",
    "    #\n",
    "    if Z is None: # case when there is only one input (X)\n",
    "        Z=X;\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    if Z is None: \n",
    "        return X.dot(X.T)\n",
    "    else: \n",
    "        return X.dot(Z.T)\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-innerproduct_selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Run this self-test cell to check your code\n",
    "\n",
    "def innerprod_0():\n",
    "    # test the output dimensions of innerproduct with one input matrix\n",
    "    X = np.random.rand(700,10) # define 700 random inputs X\n",
    "    test = (innerproduct(X).shape==700,700)    # check if inner-product matrix has dimension 700x700\n",
    "    return test\n",
    "\n",
    "def innerprod_1():\n",
    "    # test the output dimensions of innerproduct with two matrices\n",
    "    X = np.random.rand(700,10) # define 700 random inputs X\n",
    "    Z = np.random.rand(200,10) # define 200 random inputs Z \n",
    "    test=(innerproduct(X,Z).shape ==(700,200)) # check if inner-product matrix has dimensions 700x200\n",
    "    return test\n",
    "\n",
    "def innerprod_2():\n",
    "    X = np.random.rand(700,100) # define 700 random inputs X\n",
    "    IP1 = innerproduct(X) # compute inner-product matrix with YOUR code\n",
    "    IP2 = innerproduct_grader(X) # compute inner-product matrix with OUR code\n",
    "    test = np.linalg.norm(IP1 - IP2) # compute the norm of the difference\n",
    "    return test<1e-5 # this norm should be essentially 0\n",
    "\n",
    "def innerprod_3():\n",
    "    X = np.random.rand(700,100) # define 700 random inputs X\n",
    "    Z = np.random.rand(300,100) # define 300 random inputs X\n",
    "    IP1 = innerproduct(X,Z) # compute inner-product matrix with YOUR code\n",
    "    IP2 = innerproduct_grader(X,Z) # compute inner-product matrix with OUR code\n",
    "    test = np.linalg.norm(IP1 - IP2) # compute the norm of the difference\n",
    "    return test<1e-5 # this norm should be essentially 0\n",
    "\n",
    "\n",
    "runtest(innerprod_0,'innerprod_0 Dimensions with 1 Matrix')\n",
    "runtest(innerprod_1,'innerprod_1 Dimensions with 2 Matrices')\n",
    "runtest(innerprod_2,'innerprod_2 Correctness with 1 Matrix')\n",
    "runtest(innerprod_3,'innerprod_3 Correctness with 2 Matrices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-innerprod1_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs innerprod_1\n",
    "### BEGIN HIDDEN TESTS\n",
    "X = np.random.rand(700,100)\n",
    "IP1 = innerproduct(X)\n",
    "IP2 = innerproduct_grader(X)\n",
    "\n",
    "test = np.linalg.norm(IP1 - IP2)\n",
    "assert test<1e-5\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-innerprod2_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 Point\n",
    "# runs innerprod_2\n",
    "### BEGIN HIDDEN TESTS\n",
    "X = np.random.rand(700,100)\n",
    "Z = np.random.rand(300,100)\n",
    "IP1 = innerproduct(X,Z)\n",
    "IP2 = innerproduct_grader(X,Z)\n",
    "\n",
    "test = np.linalg.norm(IP1 - IP2)\n",
    "assert test<1e-5\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ac71223b7dc5fc32",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3>Exercise 2: Derive the Distance Matrix</h3>\n",
    "\n",
    "Let us define two new matrices $S,R\\in{\\cal R}^{n\\times m}$ \n",
    "\t\t$$S_{ij}=\\mathbf{x}_i\\mathbf{x}_i^\\top, \\ \\ R_{ij}=\\mathbf{z}_j\\mathbf{z}_j^\\top.$$\n",
    " \tShow that the <em>squared</em>-euclidean matrix $D^2\\in{\\cal R}^{n\\times m}$, defined as\n",
    "\t\t$$D^2_{ij}=(\\mathbf{x}_i-\\mathbf{z}_j)(\\mathbf{x}_i-\\mathbf{z}_j)^\\top,$$\n",
    "\tcan be expressed as a linear combination of the matrix $S, G, R$. (Hint: It might help to first express $D^2_{ij}$ in terms of inner-products.) What do you need to do to obtain the true Euclidean distance matrix $D$?</p></td>\n",
    "\t\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a9a1f2c25b626f9d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3>Exercise 3: Implement <code>l2distance</code></h3>\n",
    "\n",
    "<p>Implement the function <strong><code>l2distance</code></strong>, which computes the Euclidean distance matrix $D$ without a single loop. (Hint: Make sure that when you take the square root of the squared distance matrix, ensure that all entries are non-negative. Sometimes very small numvers can be non-negative due to numerical precision, you can just set them to 0.)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-l2distance",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def l2distance(X,Z=None):\n",
    "    # function D=l2distance(X,Z)\n",
    "    #\n",
    "    # Computes the Euclidean distance matrix.\n",
    "    # Syntax:\n",
    "    # D=l2distance(X,Z)\n",
    "    # Input:\n",
    "    # X: nxd data matrix with n vectors (rows) of dimensionality d\n",
    "    # Z: mxd data matrix with m vectors (rows) of dimensionality d\n",
    "    #\n",
    "    # Output:\n",
    "    # Matrix D of size nxm\n",
    "    # D(i,j) is the Euclidean distance of X(i,:) and Z(j,:)\n",
    "    #\n",
    "    # call with only one input:\n",
    "    # l2distance(X)=l2distance(X,X)\n",
    "    #\n",
    "    if Z is None:\n",
    "        Z=X;\n",
    "\n",
    "    n,d1=X.shape\n",
    "    m,d2=Z.shape\n",
    "    assert (d1==d2), \"Dimensions of input vectors must match!\"\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    D = -2*X.dot(Z.T)\n",
    "    s1 = np.sum(X**2,axis=1)\n",
    "    s2 = np.sum(Z**2,axis=1)\n",
    "    s1 = np.expand_dims(s1,1)\n",
    "    s2 = np.expand_dims(s2,1)\n",
    "    D = s1 + D\n",
    "    D = s2.T + D\n",
    "    D = np.maximum(D, 0)\n",
    "    D = np.sqrt(D)\n",
    "    return D\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-l2distance_selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Run this self-test cell to check your code\n",
    "\n",
    "def distance_accuracy(): \n",
    "    X = np.random.rand(700,100) # define random inputs\n",
    "    D1 = l2distance(X) # compute distances from your solutions\n",
    "    D2 = l2distance_grader(X) #compute distance from ground truth\n",
    "    test = np.linalg.norm(D1 - D2) # compare the two\n",
    "    return test<1e-5 # difference should be small\n",
    "\n",
    "def distance_squareroot():  \n",
    "    X = np.random.rand(700,100) # define random inputs\n",
    "    D1 = l2distance(X) # compute distances from your solutions\n",
    "    D2sq = l2distance_grader(X)**2 #compute distance from ground truth *but square them*\n",
    "    test = np.linalg.norm(D1 - D2sq) # compare the two\n",
    "    return test>1e-5 # difference should be big\n",
    "\n",
    "def dimensions():\n",
    "    X = np.random.rand(700,100) # define random inputs\n",
    "    Z = np.random.rand(800,100) # define random inputs\n",
    "    n,d1=X.shape\n",
    "    m,d2=Z.shape    \n",
    "    D1 = l2distance(X,Z) # compute distances from your solutions\n",
    "    o1,o2=D1.shape\n",
    "    return (o1==n) and (o2==m)\n",
    "\n",
    "def matrix_dist_accuracy():\n",
    "    X = np.random.rand(700,100)\n",
    "    Z = np.random.rand(300,100)\n",
    "    D1Z = l2distance(X,Z)\n",
    "    D2Z = l2distance_grader(X,Z)\n",
    "    test = np.linalg.norm(D1Z - D2Z)\n",
    "    return test<1e-5\n",
    "\n",
    "runtest(distance_accuracy,'distance_accuracy')\n",
    "runtest(distance_squareroot,'distance_squareroot')\n",
    "runtest(dimensions,'dimensions')\n",
    "runtest(matrix_dist_accuracy,'matrix_dist_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-distance_accuracy_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 Point\n",
    "# runs distance_accuracy\n",
    "### BEGIN HIDDEN TESTS\n",
    "X = np.random.rand(700,100)\n",
    "D1 = l2distance(X)\n",
    "D2 = l2distance_grader(X)\n",
    "                      \n",
    "test = np.linalg.norm(D1 - D2)\n",
    "assert test<1e-5\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-distance_squareroot_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 Point\n",
    "# runs distance_squareroot\n",
    "### BEGIN HIDDEN TESTS\n",
    "X = np.random.rand(700,100)\n",
    "D1 = l2distance(X)\n",
    "D2sq = l2distance_grader(X)**2\n",
    "\n",
    "test = np.linalg.norm(D1 - D2sq)\n",
    "assert test>1e-5\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-dimensions_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 Point\n",
    "# runs dimensions\n",
    "### BEGIN HIDDEN TESTS\n",
    "X = np.random.rand(700,100) # define random inputs\n",
    "Z = np.random.rand(800,100) # define random inputs\n",
    "n,d1=X.shape\n",
    "m,d2=Z.shape    \n",
    "D1 = l2distance(X,Z) # compute distances from your solutions\n",
    "o1,o2=D1.shape\n",
    "\n",
    "assert (o1==n) and (o2==m)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-matrix_dist_accuracy_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 Point\n",
    "# runs matrix_dist_accuracy\n",
    "### BEGIN HIDDEN TESTS\n",
    "X = np.random.rand(700,100)\n",
    "Z = np.random.rand(300,100)\n",
    "                      \n",
    "D1Z = l2distance(X,Z)\n",
    "D2Z = l2distance_grader(X,Z)\n",
    "    \n",
    "test = np.linalg.norm(D1Z - D2Z)\n",
    "assert test<1e-5\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aea442b17bc8042e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Let's now compare the speed of your l2-distance function against the previous naïve implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "current_time = lambda: int(round(time.time() * 1000))\n",
    "\n",
    "X=np.random.rand(700,100)\n",
    "Z=np.random.rand(300,100)\n",
    "\n",
    "print(\"Running the naïve version...\")\n",
    "before = current_time()\n",
    "Dslow=l2distanceSlow(X)\n",
    "after = current_time()\n",
    "t_slow = after - before\n",
    "print(\"{:2.0f} ms\".format(t_slow))\n",
    "\n",
    "print(\"Running the vectorized version...\")\n",
    "before = current_time()\n",
    "Dfast=l2distance(X)\n",
    "after = current_time()\n",
    "t_fast = after - before\n",
    "print(\"{:2.0f} ms\".format(t_fast))\n",
    "\n",
    "\n",
    "speedup = t_slow / t_fast\n",
    "print(\"The two methods should deviate by very little: {:05.6f}\".format(norm(Dfast-Dslow)))\n",
    "print(\"but your NumPy code was {:05.2f} times faster!\".format(speedup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ac9dc5c3b6c424f3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "How much faster is your code now? With this implementation, you should easily be able to compute the distances between <strong>many more</strong> vectors. It should be clear now, even for small datasets, that the for-loop based implementation could take several days or even weeks to perform basic operations that take seconds or minutes with well-written NumPy code."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
