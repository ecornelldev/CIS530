{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-da909ed2b39a0d76",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h2>About this Project</h2>\n",
    "<p>In this project, you will build an email spam filter by implementing ridge regression loss and gradient descent. You will also have an opportunity to adjust the feature extraction and model training to improve your spam filter and test it against a hiddent dataset.</p>\n",
    "\n",
    "<h3>Evaluation</h3>\n",
    "\n",
    "<p><strong>This project must be successfully completed and submitted in order to receive credit for this course. Your score on this project will be included in your final grade calculation.</strong><p>\n",
    "    \n",
    "<p>You are expected to write code where you see <em># YOUR CODE HERE</em> within the cells of this notebook. Not all cells will be graded; code input cells followed by cells marked with <em>#Autograder test cell</em> will be graded. Upon submitting your work, the code you write at these designated positions will be assessed using an \"autograder\" that will run all test cells to assess your code. You will receive feedback from the autograder that will identify any errors in your code. Use this feedback to improve your code if you need to resubmit. Be sure not to change the names of any provided functions, classes, or variables within the existing code cells, as this will interfere with the autograder. Also, remember to execute all code cells sequentially, not just those you’ve edited, to ensure your code runs properly.</p>\n",
    "    \n",
    "<p>You can resubmit your work as many times as necessary before the submission deadline. If you experience difficulty or have questions about this exercise, use the Q&A discussion board to engage with your peers or seek assistance from the instructor.<p>\n",
    "\n",
    "<p>Before starting your work, please review <a href=\"https://s3.amazonaws.com/ecornell/global/eCornellPlagiarismPolicy.pdf\">eCornell's policy regarding plagiarism</a> (the presentation of someone else's work as your own without source credit).</p>\n",
    "\n",
    "<h3>Submit Code for Autograder Feedback</h3>\n",
    "\n",
    "<p>Once you have completed your work on this notebook, you will submit your code for autograder review. Follow these steps:</p>\n",
    "\n",
    "<ol>\n",
    "  <li><strong>Save your notebook.</strong></li>\n",
    "  <li><strong>Mark as Completed —</strong> In the blue menu bar along the top of this code exercise window, you’ll see a menu item called <strong>Education</strong>. In the <strong>Education</strong> menu, click <strong>Mark as Completed</strong> to submit your code for autograder/instructor review. This process will take a moment and a progress bar will show you the status of your submission.</li>\n",
    "\t<li><strong>Review your results —</strong> Once your work is marked as complete, the results of the autograder will automatically be presented in a new tab within the code exercise window. You can click on the assessment name in this feedback window to see more details regarding specific feedback/errors in your code submission.</li>\n",
    "  <li><strong>Repeat, if necessary —</strong> The Jupyter notebook will always remain accessible in the first tabbed window of the exercise. To reattempt the work, you will first need to click <strong>Mark as Uncompleted</strong> in the <strong>Education</strong> menu and then proceed to make edits to the notebook. Once you are ready to resubmit, follow steps one through three. You can repeat this procedure as many times as necessary.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e18e4b15769199ac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h2>Getting Started</h2>\n",
    "    \n",
    "<h3>Computing Derivatives</h3>\n",
    "\n",
    "<p>  In this project you will need the gradient for several loss functions with respect to the weight vector $\\mathbf{w}$:\n",
    "</p>\n",
    "\n",
    "<ol>\n",
    "    <li> Ridge Regression: ${\\cal L}(\\mathbf{w})=\\frac{1}{n}\\sum_{i=1}^n (\\mathbf{w}^\\top \\mathbf{x}_i-y_i)^2+\\lambda \\|\\mathbf{w}\\|_2^2$ </li>\n",
    "    <li> L2-regularized Logistic Regression (assumes $y_i\\in\\{+1,-1\\}$): ${\\cal L}(\\mathbf{w})=\\frac{1}{n} \\sum_{i=1}^n \\log(1+\\exp{(-y_i \\mathbf{w}^\\top \\mathbf{x}_i)}) +\\lambda \\|\\mathbf{w}\\|_2^2$ \n",
    "</ol>  \n",
    "\n",
    "<p> Note:    $\\|\\mathbf{w}\\|_2^2=\\mathbf{w}^\\top \\mathbf{w}$ and  $\\lambda$ are non-negative constants. You have either seen or derived the gradients of these two functions before. You can either refer back to the previous sections or derive the gradients again!</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-41b1914a70420412",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3>Python Initialization</h3> \n",
    "\n",
    "<p>Please run the following code to initialize your Python kernel. You should be running a version of Python 3.x.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-98d2bb3db3f1a61b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running python 3.7.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.matlib import repmat\n",
    "import sys\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "import os\n",
    "sys.path.append('/home/codio/workspace/.guides/hf')\n",
    "from helper import *\n",
    "\n",
    "%matplotlib inline\n",
    "print('You\\'re running python %s' % sys.version.split(' ')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-01c849716c016538",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h2>Building an Email Spam Filter</h2>\n",
    "<p>You will now implement ridge loss and gradient descent. The following cells will walk you through steps and ask you to finish the necessary functions in a pre-defined order. Code cells requiring your input will display # YOUR CODE HERE and graded portions will be adequately labeled.<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b391de438f78ea9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3>Load the Email Data</h3>\n",
    "<p>The function below loads in pre-processed email data, where emails are represented as one-hot vectors.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f6bc5ebd3b576058",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5000 input emails.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5000, 512)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize the email and hashes the symbols into a vector\n",
    "def extract_features_naive(path, B):\n",
    "    with open(path, 'r') as email_file:\n",
    "        # initialize all-zeros feature vector\n",
    "        v = np.zeros(B)\n",
    "        email = email_file.read()\n",
    "        # breaks for non-ascii characters\n",
    "        tokens = email.split()\n",
    "        for token in tokens:\n",
    "            v[hash(token) % B] = 1\n",
    "    return v\n",
    "\n",
    "def load_spam_data(extract_features, B=512, path=\"data_train/\"):\n",
    "    '''\n",
    "    INPUT:\n",
    "    extractfeatures : function to extract features\n",
    "    B               : dimensionality of feature space\n",
    "    path            : the path of folder to be processed\n",
    "    \n",
    "    OUTPUT:\n",
    "    X, Y\n",
    "    '''\n",
    "    \n",
    "    with open(os.path.join(path, 'index'), 'r') as f:\n",
    "        all_emails = [x for x in f.read().split('\\n') if ' ' in x]\n",
    "    \n",
    "    xs = np.zeros((len(all_emails), B))\n",
    "    ys = np.zeros(len(all_emails))\n",
    "    for i, line in enumerate(all_emails):\n",
    "        label, filename = line.split(' ')\n",
    "        # make labels +1 for \"spam\" and -1 for \"ham\"\n",
    "        ys[i] = (label == 'spam') * 2 - 1\n",
    "        xs[i, :] = extract_features(os.path.join(path, filename), B)\n",
    "    print('Loaded %d input emails.' % len(ys))\n",
    "    return xs, ys\n",
    "\n",
    "X,Y = load_spam_data(extract_features_naive)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7b6213a523d63a49",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3>Split The Dataset</h3>\n",
    "\n",
    "<p>Now that you have loaded the dataset, it's time to split it into training and testing. To evaluate your algorithm you should split off 20% of this data into a testing set, leaving 80% as your training set.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-abc745535f48502d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Split data into training (xTr and yTr) and testing (xTv and yTv)\n",
    "n, d = X.shape\n",
    "# Allocate 80% of the data for training and 20% for testing\n",
    "cutoff = int(np.ceil(0.8 * n))\n",
    "# indices of training samples\n",
    "xTr = X[:cutoff,:]\n",
    "yTr = Y[:cutoff]\n",
    "# indices of testing samples\n",
    "xTv = X[cutoff:,:]\n",
    "yTv = Y[cutoff:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a1ed2fcdc58d8269",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3>Part 1 [Graded]</h3>\n",
    "\n",
    "<p>The code above should generate a training data set <code>xTr</code>, <code>yTr</code> and a validation set <code>xTv</code>, <code>yTv</code> for you. </p>\n",
    "\n",
    "<p>It is now time to implement your classifiers. You will always use the gradient descent algorithm, but with various loss functions. First implement the function <code>ridge</code>, which computes the ridge regression loss and gradient for a particular data set <code>xTr</code>, <code>yTr</code> and a weight vector <code>w</code>. Make sure you don't forget to incorporate your regularization constant $\\lambda$. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ridge",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def ridge(w, xTr, yTr, lmbda):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    w     : d   dimensional weight vector\n",
    "    xTr   : nxd dimensional matrix (each row is an input vector)\n",
    "    yTr   : n   dimensional vector (each entry is a label)\n",
    "    lmbda : regression constant (scalar)\n",
    "    \n",
    "    OUTPUTS:\n",
    "    loss     : the total loss obtained with w on xTr and yTr (scalar)\n",
    "    gradient : d dimensional gradient at w\n",
    "    \"\"\"\n",
    "    n, d = xTr.shape\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    preds = xTr @ (w)\n",
    "    diff = preds - yTr\n",
    "    loss = np.mean(diff ** 2) + lmbda * w.dot(w)\n",
    "    grad = 2.0 * (xTr.T) @(diff) /n  + 2*lmbda * w\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return loss, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5b1c7d699aa7ae90",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3>Estimating Gradient Numerically</h3>\n",
    "<p>An  alternative to  deriving the gradient analytically is to estimate it numerically. This is very slow, but it is a convenient  way to check your code for correctness.  The following function  uses numerical differentiation to evaluate the correctness of ridge.  If your code is correct, the norm difference between the two should be very small (smaller than $10^{-8}$).</p> \n",
    "<p>\n",
    "Keep in mind that this only checks if the gradient corresponds to the loss, but not if the loss is correct. The function also plots an image of the gradient values (blue) and their estimates (red). If everything is correct, these two should be right on top of each other.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dc7ad5bbc4642fb7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The norm ratio is 3.48720773410869e-10.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAF3CAYAAAARh7eaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsvX18XVd55/tbkizFErFNguUQ4lTic4HJG0l0FIYODcVpwk0pifNy0xulcIEBYqLQ1o5dB+L5zLTcxtO6il2a4jC+hQbHJmGSAE07ZVqbuq9AYskkkNSBJOCZGBycFyix4ljy0bp/7LOlreP9svbea+219t6/7+ezP5KOztln7fX2POt5nvUsIaUEIYQQQghxhw7bBSCEEEIIIfOhgkYIIYQQ4hhU0AghhBBCHIMKGiGEEEKIY1BBI4QQQghxDCpohBBCCCGOQQWNEEIIIcQxqKARQgghhDgGFTRCCCGEEMeggkYIIYQQ4hhdtguQh9e97nVyYGDAdjEIIYQQQhKZmJh4QUq5VOW9pVbQBgYGMD4+brsYhBBCCCGJCCH+l+p7jbk4hRDLhRB7hBD7hRBPCCF+u/X6HwkhnhRCfEcI8RUhxJLW6wNCiKNCiEdb12dNlY0QQgghxGVMxqAdB7BWSnkWgLcDuFkIcTaAXQDOlVK+FcD3AXwy8JlnpJQXtK6PGSwbIYQQQoizGFPQpJSHpJT7Wr+/DGA/gDdIKf9WSnm89bZvATjDVBkIIYQQQspIITFoQogBABcCeLjtX/8RwJcCfw8KIb4N4OcA/pOU8p/Sftf09DQOHjyIV199NWNp681JJ52EM844AwsWLLBdFEIIIaS2GFfQhBCvAfAggNVSyp8HXt8Azw26s/XSIQBnSilfFEI0AHxVCHFO8DOtz90I4EYAOPPMM0/4voMHD+Lkk0/GwMAAhBBGnqmqSCnx4osv4uDBgxgcHLRdHEIIIaS2GM2DJoRYAE852yml/HLg9Q8AeC+A35BSSgCQUh6TUr7Y+n0CwDMA3tx+TynlNinlsJRyeOnSE3eqvvrqqzj11FOpnGVACIFTTz2V1kdCCCHEMiZ3cQoAnwOwX0q5OfD65QBuBXCllPKVwOtLhRCdrd/fCOBNAH6Q8bvzFL3WsO4IIYQQ+5i0oL0DwPsBXBJInfEeAH8K4GQAu9rSabwTwHeEEI8BeADAx6SULxksX2V56KGH8Ad/8Ae2i0EIIYSQjBiLQZNS/jOAMHPMX0e8/0F47tDCmJkB7r0X2LIFePZZYPlyYM0aYGQE6CjpIVjHjx/HlVdeiSuvvNJ2UQghhBCSkZKqIfmZmQGuuQZYtQqYmAAOH/Z+rloFXHut9/+sHDhwAGeddRY++tGP4pxzzsG73/1uHD16FO9617tmTz544YUX4B9Tdffdd+Oqq67CFVdcgcHBQfzpn/4pNm/ejAsvvBBvf/vb8dJLniHxmWeeweWXX45Go4GLL74YTz75JADggx/8IG655RasWLECt956K+6++258/OMfBwD85Cc/wdVXX43zzz8f559/Pr7xjW9kfzBCCCGEFEJtFbR77wV27wYmJ+e/PjkJ7NoF3Hdfvvs/9dRTuPnmm/HEE09gyZIlePDBeOPg448/ji9+8Yt45JFHsGHDBvT29uLb3/42fvEXfxHbt28HANx444248847MTExgbGxMYyOjs5+/vvf/z52796NO+64Y959f+u3fgu//Mu/jMceewz79u3DOeeck+/BNDIzA+zcCQwPA8uWeT937synHFcB1gshHAeE1FZB27LlROXMZ3IS2Lw5/H+qDA4O4oILLgAANBoNHDhwIPb9K1aswMknn4ylS5di8eLFuOKKKwAA5513Hg4cOIAjR47gG9/4Bq677jpccMEFWLVqFQ4dOjT7+euuuw6dnZ0n3Pfv/u7vcNNNNwEAOjs7sXjx4nwPpgmTFkwb6BImVasXQrLAcaAGldhqU1sF7dln4/9/8GC++/f09Mz+3tnZiePHj6OrqwszrZHTnsoi+P6Ojo7Zvzs6OnD8+HHMzMxgyZIlePTRR2ev/fv3z36mr68vX4ELxrdgTk1OYRPWYS8a2IR1mJqc0mLBLBKdwiRPvXCyJlWhSvODKbLMO5wjykVtFbTly+P/f4aBA6gGBgYwMTEBAHjggQdSfXbRokUYHBzE/fffD8BLKvvYY48lfu5XfuVXcNdddwEAms0mfv7znyd8ohh8C+btuA2j2Iph7MMotuJ23KbFglkkOoVJ1nqhxWEOCqHyU6X5wRRp5x3OEeWjtgramjVAlNGprw+45Rb937lu3Trcdddd+A//4T/ghRdeSP35nTt34nOf+xzOP/98nHPOOfiLv/iLxM98+tOfxp49e3Deeeeh0WjgiSeeyFJ07fgWzBXYgz4cBQD04ShWYA+A/BbMItEpTLLWCy0OHhRC1aBK84Mp0s47nCNKiJSytFej0ZDt/Ou//usJr4XRbEq5cqWUfX1SAnNXX5+UV13l/b+uqNZhVppNKRcv9up7E9bKI1goJSAnsVBuwloJSBnStM7S3+89y14MzetMezEkASmXLVO/V6ORrV7CPnekpPWZhx07vDG8AMfkJqyVezEkN2GtXIBjsq9Pyp07bZeQqJB1HNSJtPMO5wg3ADAuFXWc2lrQOjqAL38Z2LYNaDQ8V0ij4f394IPlzYNWBu69F3j1VWABptCBJl7GyXgO/fgsVmEDNqKnx4wF0xS+u3wPVmASCwEAr2Ah9mAFgHTuct+yuwEbsRWjGMcQPoNRbMDGWMsuLQ4eNl1jtl2rtr9fJ1nHQZ1IO+9wjighqpqci1ceCxqJxnQdJq3kFi8ulwVTp9Umq2WXFgcPndbMNNi2yNv+ft1U7XlMkHbe4RzhBkhhQbOuZOW5qKCZwXQdJgnR/n6jX68d3cKk2fQm10bDUygaDe/vuPvQtedhSwjZrn/b32+CLOOgTqSdd6rYR8oIFTSSCxsWtLKv5GwLE1ocPGwJIdvxPTq/v9n06rHR8BZLjYb3d136UJlIM+/UaY5wuQ9TQSO5MF2HXMmZwbaS6AK2hJAt16ru76+TEK8jdZgjXO/DaRQ0hsKTwhkZAS69FOju68Z6jOEiTGA9xtDd143LLgOuv952CctJRwdwww3A+Djw3HPezxtuqNeGF1ubf3RuFLH5/UzFUG3qMEdUqg+ranIuXnWxoP35n/+5vPnmm1N9pq+vT0op5Y9+9CN57bXXpvpsEXVYh5UcqQ+2rcK6vt+2q5aQvLjeh5HCgtZlW0EkZjn99NNTn1pQBP5K7oYbbJeEkPyMjAD33w/s3t2N9ZNjs6/39aEQq7Cu72cqhnIyM+NZjrZs8dpw+XIvVcnISLWsYypUqQ/XrOmKYXJyEr/2a7+G888/H+eeey6+9KUv4eqrr579/65du3DNNdcAAF7zmtfg1ltvRaPRwKWXXopHHnkE73rXu/DGN74RDz300Oxnnn32WVx++eV4y1vegt/7vd+bfX3z5s0499xzce655+KP//iPTyjLgQMHcO655wLwjnpat24dzjvvPLz1rW/FnXfeaaoKCKkVtvMq6vp+265akh6enjGfSvVhVVObi5cWF+exY1KuXSvl0JD389ixdJ8P4YEHHpAf+chHZv/+2c9+Jt/ylrfIw4cPSymlHBkZkQ899JCUUkoA8q//+q+llFJeddVV8rLLLpNTU1Py0Ucfleeff76U0nNxnnbaafKFF16Qr7zyijznnHPk3r175fj4uDz33HPlkSNH5MsvvyzPPvtsuW/fPinlnIvzhz/8oTznnHOklFJu3bpVXnPNNXJ6elpKKeWLL74YWv4quokJIcnYdtWS9LDN5uN6fYAuzhTcdhuwdStw9Ciwf7/32thY/GcSOO+887Bu3TrceuuteO9734uLL74Y73//+7Fjxw586EMfwje/+U1s374dANDd3Y3LL7989nM9PT1YsGABzjvvPBw4cGD2npdddhlOPfVUAMA111yDf/7nf4YQAldffTX6WoeKXnPNNfinf/onXHjhhaHl2r17Nz72sY+hq8tr9lNOOSXXcxJCqoVtVy1Jj396xqbW6Rl9OIqz4Mmy9ZNj2Ly5XqEkVerDdHHu2eMpZ4D3c8+e3Ld885vfjImJCZx33nn45Cc/iU996lP40Ic+hB07duDee+/FddddN6skLViwAEIIAEBHRwd6enpmfz9+/PjsPf33BP/2lHF1pJQn3IcQl6nS8UVlwLarlqSnSjFXOqhSHy5RUQ2xYgWw0PNTY+FC7++c/PjHP0Zvby/e9773Yd26ddi3bx9OP/10nH766fj93/99fPCDH0x9z127duGll17C0aNH8dWvfhXveMc78M53vhNf/epX8corr2BychJf+cpXcPHFF0fe493vfjc++9nPzip+L730UtZHJMQ4jK2xQ1wqBirM7lGpmCtNVCWdCF2cGzd6P/fs8ZQz/+8cfPe738Xv/M7voKOjAwsWLMBdd90FAPiN3/gNPP/88zj77LNT3/OXfumX8P73vx9PP/00brjhBgwPDwMAPvjBD+Jtb3sbAOAjH/lIpHvT///3v/99vPWtb8WCBQvw0Y9+FB//+MczPKFduGOpHszPZ3QbVmAP9mAFNkxuxK5d3bjvvnq5bmzjK8y7d3suNcBTmletAh54oHzWiaqwZo3XBhsmPdk1O054sHz5UQ1Wc/EqWx60m2++Wf7Zn/2Z7WIk4nIdupgl2uVjRcqM6/mM6obrwdd1xcU5kUQDniTgHo1GA9/5znfwvve9z3ZRSo1rWaLphjMHY2vcwg9Gv70VjD6MfRjFVtyO2zA5CWzebLuE9aRKMVdkPnRxFsTExITtIlQC13Ys0Q1njuXLPYV3D1bgLOxHH47WPrbGJlSY3YWJv6sJFTRSKlwTEq4pjFWCsTVuQYWZkGKppIImmU4iMzJl6o6icU1IuKYwVokq5TOqAlSYCSmWynmnTzrpJLz44ovOKxouIqXEiy++iJNOOsl2USJZs8YT0BuwEVsxinEM4TMYtSYkuMXdHIytcYuREeDSS4Huvm6sxxguwgTWYwzdfd1UmAkxgCizIjM8PCzHx8fnvTY9PY2DBw/i1VdftVSqcnPSSSfhjDPOwIIFC2wXJZSwrf7AnFWlaMG9c6dnVZianMLtwRg0bER3Xze2baOLk1SHmRlvI87mzZ51+IwzvEXR9ddTYSZEBSHEhJRyWOm9VVPQSPVxSUi4pjASQghxlzQKGkVHxali5m+XskTTDUcIIcQEtKBVGFp3CCGEEHegBY0AiE/q+tBDwGtfWw2LGiGEEFI1Kplmg3jE5uiaGcPPfz6X9Z5n6RFCCCHuQHFcYaJydF2CrztxTBIhhBBCwqGCVhHCNgP09Xn/a8/R1URnKc7Sq+IGB0IIIUQFYy5OIcRyANsBnAZgBsA2KeWnhRCnAPgSgAEABwD8upTyp8JL/f9pAO8B8AqAD0op95kqX5UI2wxw+DDQ0wN0dgIbmvMzf1+Cv3M+633UM9EdSwghpA6YFHHHAayVUp4F4O0AbhZCnA3gEwC+LqV8E4Cvt/4GgF8F8KbWdSOAuwyWrVJEbQaYOTYFAOjomZ/5++9wifNZ7+M2ONAd6y60ehJCiB6MWdCklIcAHGr9/rIQYj+ANwBYCeBdrbd9AcDfA7i19fp26eX9+JYQYokQ4vWt+5AYYjcDNMdw5pnAKacATz0FHDkCbJhx/yw9HkJePmj1JIQQfRQyXQohBgBcCOBhAMt8pav1s7/1tjcAeDbwsYOt10gCSQd2v/KKl8z1pz8FrriiHGfp8RDy8kGrJyGE6MO4giaEeA2ABwGsllL+PO6tIa+dkEVXCHGjEGJcCDH+/PPP6ypmqVE9sLtMWe95CHn58K2et7esnq5vQiGEEJcxmgdNCLEAnnK2U0r55dbLP/Fdl0KI1wM43Hr9IIDlgY+fAeDH7feUUm4DsA3wThIwVvgSsWaN50baMJnsuvSPSXLdPZjmmYgb0OpJCCH6MGYzae3K/ByA/VLK4Nr5IQAfaP3+AQB/EXj9/xEebwfwb4w/U2NkBLj00nK4LlXR9UwMWi8OWj0JIUQfJp1a7wDwfgCXCCEebV3vAfAHAC4TQjwF4LLW3wDw1wB+AOBpAP8fgFGDZasUZXJdqqLjmfyg9VWrvBMTDh+eOznh2muppOlmzRov994GbMRWjGIcQ/gMRrEBG9HTA7z0krqSTMWaEFJ3eFi6JWZmvKDqLVs819Dy5Z6AGxkpp0LlIjt3esrY1OQUbsdt89yk3X3d2LbNfVdvmQjbxQl4ufgAoNmce62vD7jssnBlO+o+cZ8hhJSfOsjFNIelQ0pZ2qvRaEiXaDal3LFDykZDyv5+7+eOHd7r7e9buVLKvj4pgbmrr0/Kq6468f0kG42GV6+bsFYewUIpAXkEC+UmrJWA93+il2ZTyp07vbpdtkzKgQEpe3qkXIBjchPWyr0YkpuwVi7AMdnX5723nR07vLGQ5jOEkHJTF7kIYFwq6jjWlaw8l0sKWprORQFUDP39XhvsxdC8RtmLIQl4CgQxSxYlmYo1IfWjLnIxjYJWEaOhfdLkgHIpHUGVY30YtG6fLDs7uRuUkPrhklx0BSpomkjTuVwRQFUPoo8LWg+m6qiykmqbLEoyFWtC6ocrctElqKBpIk3nckUAVT3zu0qqjqorqbZRVZLzfoYQUm5ckYtOoeoLdfFyKQYtLG5mMiJuxhVfex1ifdqD1hsN728/JtCVtqgqWQJ/6xIsXDdUN1GRelKXuRjcJFA8aTqXKwKIQfT1UFJtk6Qk6/oMcRdX5jziLnXpI1TQLJC2c7kggNJY/aoKlVRCzFMX6wjJhwty0TRpFDSjZ3HWCT/z/X33eRsCDh70fOa33OLFOrUn2XPhTEyed+nFPRw+7MU9nIX96MNRxj2Q1NQhwWYe/E1Um1qbqPpwFGdhPwBg/eQYNm9m0mjihlx0CZ4kUGOYsZ2nDZD8cBwls2yZtxDaiwaGsW/29XEM4SJMYNky4LnnLBaQkIJIc5JAzaeNelPFMzzTUsWD5kmxVH03tA64Q4+Q9NRABJM4fJPy+Li3gh0f9/7WqZy5nGeMSirJSxUSbJoeo0ydQkh66OLUBGNQwqH7h1SdsrvvihijnAcI8aCLs2CY7DQaun9I1Sm7+y7vGFWxvtFSTUgGVLd7uni5kmaDW8ijYZ4xUnXKPv7zjNG65K4iRBfgYenFUoUYFFPwfDVSdcq+0STPGKWFnBBzUEHTAJWQaMru/iEkibK77/KMUS5OCTEHE9VqgMlOo2EyXFIHypxgM88Y5eKUEHNQQdMAlZBoRkaA++8Hdu/uxvrJsdnX/d1brrt/CKk6ecYoF6eEmMNx43s5KHsMiknK7v4hpOrkGaOu5DdzOdciIVlhHjRNzMyon8NJCCFVwIX8Zi6UgRBVmAfNAkVk5CeEEJdwwULOnaSkqtCCRgghpLQMD3uJwTdhHUaxFX04ikksxFaMYj3G0Gh4C2ZCXIAWNEIIIbWAO0lJVaGCRgghpLQw1yKpKlTQCCGElBZXdpJWCe6KdQPGoBFCCCkt3MWpF9anWRiDRkiF4GqWkGhc2ElaJbgr1h1oQSPEYbiaJYQUCXfFmoUWNEIqAlezhJAiKcuu2Dp4FngWJyEOs2WLZznbhNtmV7NnYT8AYP3kGDZvLucB3YQQNynD+aphnoXDh70zsR94oDqehQo8AiHVpSyrWUJINSjDrti6eBZoQSPEYcqwmiWEVIeREeD++4Hdu7uxfnJs9nU/7vX66y0WrkVdPAu0oBHiMGVYzRJCqkMZdsXWxbNACxohDlOG1axtZmY8l8eWLd7EvXy5p9iOjLghTAgpGx0dngXKVStUXTwLnL5ILSnLDqAyrGZt4gcLr1rlpQY4fNj7uWoVcO217rUnISQ/dfEsGMuDJoT4PID3AjgspTy39dqXALyl9ZYlAH4mpbxACDEAYD+A77X+9y0p5ceSvoN50EgWmFusOuzc6SljU5NTuB23YQX2YA9WYAM2oruvG9u2uWsFMAGtiaQOlHkOdyUP2t0ALg++IKX8v6WUF0gpLwDwIIAvB/79jP8/FeWMkKzUZQdQHfCDhW9vBQsPYx9GsRW34zZMTgKbN9suYXHQmkjqQl08C8YeQ0r5jwBeCvufEEIA+HUA95r6fkKioFCvDnUJFlaBCw9SJ/w4ufFx4LnnvJ833FAd5QywF4N2MYCfSCmfCrw2KIT4thDiH4QQF1sqF6kBFOrVYfly7+cerMAkFgJAJYOFVeDCg5BqYUtBG8F869khAGdKKS8EcAuALwohFoV9UAhxoxBiXAgx/vzzzxdQVFI1koT6iy+6u2mAzKcuwcIqcOFBSLUoXEETQnQBuAbAl/zXpJTHpJQvtn6fAPAMgDeHfV5KuU1KOSylHF66dGkRRXaKsuw+dJk4oQ4Ax48zdqcsjIwAl14KdPd1Yz3GcBEmsB5j6O7rrl0aEloTCakWNixolwJ4Uko5u54TQiwVQnS2fn8jgDcB+IGFsjkNg4D1ECXUATB2xzC6Fxh1CRZWgdZEQiqGlNLIBc+FeQjANICDAD7cev1uAB9re++1AJ4A8BiAfQCuUPmORqMh68SOHVL29Um5AMfkJqyVezEkN2GtXIBjsq9Pyp07bZewPDSbXn01GlJ2dUkJSLkJa+URLJQSkEewUG7CWgl47yH5aTalXLnS68PA3NXXJ+VVV3n/J9lh/ZI0NJueTGk0pOzv937u2MF+YhoA41JRjzKWB60I6pYHbXjYs5htwrrZ88cmsRBbMYr1GEOj4e1kIelYtsyzRu5FA8PYN/v6OIZwESawbJm3S4jkgznLzDMz41l8N2/2Ys7OOMOznF1/fb2siSSeMucRKzuu5EEjmmEQsBkYu1MMOnYZMgYznjqkHiD5YUqWcsBhWyKoSJiBsTvFkHeBwRhMUkZcXFQwJUs5oIJWIqhImIE7AYsh7wKDq35SNlxdVNAbUxJUg9VcvOq2SYBBwOYIbhpYtsz7uXOn3jqte1Bu3k0ujQY3c6Sh7v3NBVzd2BU2liY5lgoBKTYJWFey8lx1U9CkLEaRIPqhcp2/Dvr7vffvxdC8G+zFkAS88UA82N/cwNVFhauKYx1Io6DRxVkyGARcTuiey5+zjDGY6rC/uYGrrkSGdZQEVU3OxauOFjRiFlNuIVdX0mWCq3512N/cwGVXIr0xdgDzoBGSHpO5gZhrLT952mdmxrMqbdniWTWWL/c23YyMVNP6zP7mBsz9R9phHjRCMmDSLUT3XD58BevZZ4HOTqC3F1i0SM1F6upOOpOwv7kBXYkkF6qmNhcvujiJTky6heiey07egPc61n0dn9lV6EokQUAXJyHpMekW4tEq2cnrJqrjEWnsb4S4CV2cJcfFzNN1wKRbKO8OxjqTN+u5qzvpTKKrv3EuIsQiqqY2F68qujhN5S9i0spk6BZyk7z5z1zeSecyzKVGiH7APGjlxUSgeh2DpLPAgF43yWvZ5BFp2WAuNUIso6rJuXhV0YJmIlCdliF1GNDrHnn7Ly1B2WAuNUL0A24SKC8mAtXrGCRNqoOOgPeZGc/is3mzF3N2xhme5ez66xn/FwVzqRGiH24SKDEmAtXrGCRNqoOOgHcekZYe5lIjxC5dtgtA5rNmjRcbtmFyIwDMSymQNV5m+XJvJbwHK3AW9qMPRznRklLhK1jMul4cJuYiQog6dHE6hon8RTxuhBCSFuZSI0Q/aVycVNAcRHe8DCdaQkgWGLtHiF6ooJET4ERLCCGE2IWbBMgJ2AiSZhZyQgghJBvcJECMEOZWPXzYi4V74AG6VQkhhJA4KCKJEZiFnBBCCMkOFTRihLwHXJcduncJIYTkgS5OYoQ6J8ele5cQQkheKCaIEeqchZzuXUIIsUsVvBiJFjQhhADwGwDeKKX8lBDiTACnSSkfMV46UlrqnIXcd+9uarl3+3AUZ2E/AGD95Bg2b2ZiYEIIMUVVvBgqRdwK4BcBjLT+fhnAZ4yViFSCkRHg0kuB7r5urMcYLsIE1mMM3X3duOwyL/9aFGVf+dTZvQuUv/0IIeWmKl4MFQXt30spbwbwKgBIKX8KoNtoqUjpyXrAtb/yWbUKmJjwVj0TE97f115bDiFfZ/duFdqPkDxwgWKfqmxSU1HQpoUQnQAkAAghlgJgV8tA3QZuluS4VVj5rFnjHaO1ARuxFaMYxxA+g9FauHer0H6EZIULFDeojBdDShl7wYs/ewjAQQC3A/gegOuSPlfE1Wg0ZFloNqVcuVLKvj4pgbmrr0/Kq67y/k+kbDS8etmEtfIIFkoJyCNYKDdhrQS8/7tOndu6Cu1HSFZ27PDG+QIck5uwVu7FkNyEtXIBjsm+Pil37rRdwnoQNg9NOjIPARiXijpOogVNSrkTwHoA/xXAIQBXSSnvN6UwVhVaFtSowsonq3u3ClSh/UwyMwPccw8wOAgsWOBdb3yj9xqtK+WnKq61slMVL0aiqGjt2nwFwF/Cs6RNtl4jKeDAVaMq8Vs2zj51gaq0nwlmZoCrrwY+9CHgwAHg+HHv+uEPvdfoAis/KguUuoW62CDPJjWXUBEX/wPAX7V+fh3ADwB8zWShqggtC2pUZeVTV9h+0dx7L/A3fwN0NKcwhjU4hGU4hGW4A2vQ0ZzC175mxpJOhaA4khYob3gDY9SKoDJeDFVfqH8BGALw3xTe93kAhwE8HnjtdwH8CMCjres9gf99EsDT8GLc/k+VspQpBs1ln7hL1Dl+qwqw/aIJzgHH0DlbOVPoMjYPsD2KJSkGbXSUMWp1Byli0DIF5wPYp/Ced7aUuXYFbV3Ie88G8BiAHgCDAJ4B0Jn0HWVS0Bg8qk6z6dVHoyHlsmXez507KUzKAtsvnP5+b8bdi6H52hIg92JIAl596YTzTrEkKcTcREPSKGgqJwkEnRIdLaXreQXL3D8KIQaS3tdiJYD7pJTHAPxQCPE0gLcB+Kbi551nZAS4/35g9+5urJ8cm329rw+l8okXgR+/xWz75YTtF87y5Z5Law9W4K14DN1oAgCm0WUsRo+nWhSL71q77z4vrvjgQa9Nb7nFm+Nf/3rvfQx1ISqoeGJ0RZCQAAAgAElEQVRPDlw98GLRVub4zo8LIb4jhPi8EOK1rdfeAODZwHsOtl6rDJXxiRNCMrFmDdDT48Xn3YnfxHPox3Pox534ODZgI3p69MfoMfa1eOI2CNVtEw3jH3OiamrLcgEYwHwX5zIAnfAUw9sBfL71+mcAvC/wvs8BuDbinjcCGAcwfuaZZxoxQZJkmk3PfdJoeK6bRsP7u+5uLEKiaDalvPJKKTvnws9mr85OMzFhjH11izq5nBn/GA5SuDiF9/4TEUL8JVqnB0QodlcmKX8tF+dfSSnPjfufEOKTrXv+19b//gbA70opY12cw8PDcnx8PKkYRDNhB9ECc+5aWgQJCWdmBvjiF4H//J/nrFvLlwOf+pSZNCw7d3o7BKcmp3A7bsMK7MEerMAGbER3Xze2baOLs0jqNHey74UjhJiQUg4rvTlKcwPwy3GXivaHEy1orw/8vgZe3BkAnIP5mwR+gIptEqgSdVoFElJmaMVwjzJuosniMeGGiHCgw4KWFyHEvQDeBeB1AH4C4L+0/r4AnmXuAIBVUspDrfdvAPAfARwHsFpKmZhrjRY0OwwPe7l7NmHdbODxJBZiK0axHmNoNLy4C0KIfWZmooPWq2KtIebIavVbtszbFLMXDQxj3+zr4xjCRZjAsmVejF7dSGNBU9nF+SZ4xzydDeAk/3Up5RvjPielHAl5+XMx778dXlwacZCZGS/R5pYtwL7WWGPgMSHuw121JA/zjykMuConN2LXrm7cd1943wruWj4L+9GHo5XeEGEClfXTnwO4C55lawWA7QDuMVko4hb+CsrPfu0bXW3vRKryDqEqPxsheeDYKJasxxTyVBENJPlAAUy0fn438No/qfpQTV6MQSuGqJizXrxsPAYtKvZherq6sTWMGyIkHI6N4olKsJyUXJltFQ50niQA4F/gWdq+DODjAK4G8D3VLzB5UUErhqRgT1MDL26ANxrV3ajATRiEhMOxUTx5UrWUcUOEaXQraBcBeA2AM+C5Ox8E8HbVLzB5UUErhqQVlBBmBl7cZNzREa80lrlrcPcTIeFwbBQPlWK9pFHQEjcJADgupTwC4AiAD+lyrRL7BAP/n33WC+pcs8Y7liq4Kycp2HNoyMyuzdhjama847KquFGB2d8JCacqY0N17nUBHlNoD5WusFkI8aQQ4v8VQpxjvESkENoD/w8f9n6uWgVce+38gFtbwZ5JkzFgf6OCCep2HAwhKszMePMQUO6xkWbudQEeU2gRFTMbgNMA/Ba8eLTvAvhPqiY6k1fVXJw6jk9SvUcas7WtYM+k2IeOjmqa3elSIGQ+/hzU0+PNCWUeGxzf9QY6Y9DmvRk4D16Kjak0nzN1VUlB06EEpblH2lgOG8GecRNZb+/cRoGq7RDi7qd4eA5s/YibCwBPcSvL2GAcXb3RqqABOAvA7wJ4HMA/ALgJQL/qF5i8qqSg6VhVJQXVj47OTWBZt04XSZKiMj1d3R1C3P0UDpXXepKk1AwOlqftyzD3EnPoVtC+BeC3AZyuetOiriopaDpWVUn36OiYE2J5tk4XCRUVEoTuoXpSJaWmLHMvMYMxF6drV5UUNB0TUNQ9fCUtKMQo6EgZoXuoniQpNUND2e9dtMucc2+9SaOgqaTZIAWg49yysHtIeDsfR7EVALB+cgybNwOPPMKt06R8VCXNAknHmjXAjTcCG17ZCABz50HC+7ujw9v9mHZHYdhB4IcPezsqH3jAzC5Fpq0gqnCDrCPoSGXRfo9JLIRo/a9diOnaOs1z8UiR2EhBwj5un5ER4N/9O2Aa3diAjdiDFViBPbgdt2EBprB/P3DffenvO/8g8HXYiwY2YR2mJqewa1e2eybBtBVEmSQTG4DrVF6zcVXJxalzF2dYln0TMQ4M2CZFU7R7iH3cHUy4t+kyJ0UDzZsE9qm8ZuOqkoImpZ6A+GbT261ZRI4wxlKQoilaYWIfdwcTGwWqtPmAlIM0ClpkDJoQ4lcBvAfAG4QQfxL41yIAx83Y8+pNRwdwww3eleced94J/OhH5mMcYo9iasW65XkWQtrx3UP33Qds3uy56884wwsBuP56/e4h9nF30BGnW8Q9CdFF3CaBHwMYB3AlgInA6y8DWGOyUCQfRQkxBmwTG+hYyKjCPu4Oa9Z4wfsbJk/cKJD1yDkT9yREF5EKmpTyMQCPCSG+KKWcLrBMRANFCLE6rD7LdKixi5S9/urQx8uCid2P3FFJnCbJBwrgHQB2Afg+gB8A+CGAH6j6UE1eVYtBKxtVj89hgHg+qlB/Ve/jZcNE4momwyZFghQxaMJ7fzRCiCfhuTQnADQDit2LZlRGdYaHh+X4+LjtYtSWsBxCwNzqs+xbxnfu9NwfU5NTuB23zXN/dPd1Y9s2xh/FUYX6q3ofJ4QUixBiQko5rPJelanl36SUX5NSHpZSvuhfOctIKkDV8/n4AeK3twLEh7EPo9iK23EbJie9+D4STRXqr+p9nFQP5u2rDioWtD8A0AngywCO+a9LKfeZLVoytKARkyxb5sUf7UUDw5jr7uMYwkWYwLJlwHPPWSyg47D+CCkWWnzdR7cF7d8DGAawEcAdrWss9hOEVAAbWevLStiqva/P+x/rj5BisHEyAjFH4lmcUsoVRRSEENfgFnw1os4z7OkBOjuBDU3WHyFFwLx91SLRgiaEWCaE+JwQ4mutv88WQnzYfNEIscvICHDppUB3XzfWYwwXYQLrMYbuvm5uwQ8QtWqfOTYFAOjoYf0RUgS68/Yxns0uKi7OuwH8DYDTW39/H8BqUwUixBUYIK5G3GaAZhM4/XR3648CqJ6Yanfb/UlnWIZvGV+1CpiY8KziExPe39dem++ZbNdTaUjKwwFgb+vntwOvPaqax8PkxTxohNinrOcZViFPG0mPqXZ3oT/pzNtnKgegC/VkE6TIg6ayhp0UQpwKQAKAEOLtAP7NjLpICCkbZd1MwYDqemKq3V3oTzrDMkylyXGhnkpDkgYHYAjAv8BTyv4FnovzraoaoMmLFjRC9NBseivmRsOziDUa3t8qq9myZttvNLyV+yaslUewUEpAHsFCuQlrJeD9n1QPU+3uSn/SdTKCKcu4K/VkC6SwoKm9ydvteQ6AcwEsUL256YsKWjx5hC6pD3ldDmV1WZTVNUvyYardq9afwhSpSQ2KVN56KrtcS6OgRbo4hRCXtH5eA+BKAG8B8GYAV7ReIw5jMsCTVIu8Loc8mylsBguX1TVL8mGq3avWn9as8XIZbsBGbMUoxjGEz2A0d5qcPPVUO7kWpbkB+L3Wzz8PuT6vqgGavGhBi6asbidVyr6Kcokkl8PAgJl6tW15q/oYIeGYaveq9SdT4zNPPemoY9uyA7pdnK5eVNCiqbKf37ZgrxpJLgchzNSrbYHGflRPqryLUze64tmCStHSpVIuXixlT0/6esor11xoIy0KGoBb4i7VLzB5UUGLxlY8RBGrE9uCvWqETXpT6JSH0B9Zrzra2YVFhC4BRMqFqXZnfzqRKKWop0fKJUvm5g+Vesor11yQHboUtP/Sur4I4CnMncP5fQB/pvoFJi8qaNGYCvCMo6jViQuC3VWyKE7tk9Yh9MspdEXWq6521rGIsO2uIITEE6cUdXRIOTqqPl7zyjUXZIdWFyeAvwVwcuDvkwH8T9UvMHlRQYvGxkqhqO+s2m4pXWRVnPzP+e9Pqldd7Zx3snXBXUEIiSdJKeroUB+veeceF2SHbgXtSQA9gb97ADyp8LnPAzgM4PHAa3/Uut93AHwFwJLW6wMAjgJ4tHV9VqXwVNCisSG8ilqd2LAO5qEoK0+eyavZlHJwUK1edbVz3snWBXdFFLTsEeIRpRT5c0baAP88cs0F2aFbQdsA4DEAv9tyeT4K4DaFz70TXpLboIL2bgBdrd//EMAfyjkF7XHVQvsXFbR4io6HKGp14rJgbqdIRTmv4qRar7ra2cRk64Krm5Y9QuYIG6czbUpamvGaR665IDu07+IE0ADw263rQuWbxyheAK4GsDPpfXEXFTS3KGp1UiYBWOSEoCMBpEq96mznPJNt0vMuWmSnL7ggBAhxhfbx4M8ZNtyLLsgOI2k2APQDONO/FD8Tp6D9JYD3Bd43CeDbAP4BwMUq96eC5hZFCqay7JZSyTGmyw2mQ3FSqVdXFJCk542LbTHpgnTVshcGXbHENL5S1NFRzAJepTw2ZYduF+eVrV2ckwB+CKAJ4Amlm0coaC236VcAiNbfPQBObf3eAPAsgEUR97wRwDiA8TPPPNNkPZKUuLA6cY0kK0/71dHhTRjT0+m/qyjFyZV2bn/ecVwgH0ZDjuPC2Oc2XX4XApFVcKUdSfVpNr3dmh0d9hd2ttGtoD0G4FQA3279vQLANqWbhyhoAD4A4JsAemM+9/cAhpPuTwuae9henahQpNUgycoTNlkBUg4PZ0sGWZTAdaGd41bmcRYr04qsC4HIKrhiCTVF1DifnqbV0AZcEHjoVtDG5Zyi1tH6/RGlm7cpaAAuB/CvAJa2vW8pgM7W728E8CMApyTdvyoKGt0MxVH0JBEnBOeE+ElSAvI4hHwYjdn8QFkEpAuKU5E0m16sWRqLlWkXZFkUnzK5YtMSNc57e6U87bTk8c852Qx1m5/C0K2g7QbwGgB3ArgXwKcBfEPhc/cCOARgGsBBAB8G8HTLfTkvnQaAawE80VIC9wG4QqXwVVDQuKoolqKFZ1T7+le7UnEcohICskjSWqxMuyDTjmlbykBZXLFZSFoYxY1/V+dkKo3VQLeC1gegA0BXyz35W368mO2rCgqajdV2nQe6DatB2KoxmHPsOETlBGRWdJyEkDSGinBBqloKbCkDzaZ3HmIZXLFZSBrncePfRQuoq0ojSY82BQ1AJ4Ddqjcr+qqCgla0wlD3ge6K1WDHjrmA2YfRmFXSqiIgs5D3JATVz7kkgG2VZccO7yzEBTgmx7BaHkK/PIR+eQdWywU4Jnt68n+3zYVg0jiPG/8uun5d6rMkH7otaA8BWKx6wyKvKihoRSsMdR/orgRwN5tSDrWaXLUtqm75zHsSgmpsi0uLFFvKQNL3Ll48vx7S9j3bdZw0zuPGvyuLuKTnsa00mqTKc51uBe2/A/jfAD4H4E/8S/ULTF5VUNCKVhjqNtDbyaoEmJgwpqe9+/i7EOOEWJzAW7lSyu3byz+ZFdk3gwpdf7+Xj25w0D1LjyllIOl7+/vn3ptF2bK9EMwTg+bKIi6Ii0qjKWwr96bRraB9IOxS/QKTVxUUtKInsjoN9DCyDH6TE4aq5Seun3R2eu6qsk9mNvqmbWFgSxlI871Z5ijbC8E8uzhtK5dhuKg0msLF+teJVgXN5asKCpqKgNBpvUka6END+p/RNdJu9XZhwkgSeFWYzGwIobi27ejwkmuaVNJsxqCpfm8WZcuFhWDUOJ+ejh//tpX2MIq0/Nt2L9pW7k2jRUEDsBLAzYG/Hwbwg9b1f6l+gcmrCgqalPEKg+7JYscObxWpM0Fq1XFhwkgSeFWYzGwoK0ltG3dclA5s7uJU/d4sylbZLT6u5esqyvLvgnLqgnJvEl0K2r8AWB74+9HWiQJnAvi66heYvKqioMWhW2hlCU6vOy5MGEkCrwqTmQ3hENW2vpJWxJhoVwaGhjzLnWkLhqoSkkXZKvpcXtMWH9tWJb8Mpi3/rnoLyqTcJ6FLQdvb9vefBn7/luoXmLzqoKCZsN64YBEqEy5MGElpEaoymRVtuQhr25k2Ja3IeoxLbLxkibcZpGgrThahXZSyXcT3uGBVykKWed4F2eCCkmgSXQra0zH/e0b1C0xedVDQTFhvXLAIlQkXJoyoxKLH0CkPoV+OYbW8A6srN5mZpr1t/Xq1NSaSdh/29BSvFOTJT2da2S5ibLow/rOQZZ53QTaUVSFWRZeCthPAR0NeXwXgXtUvMHnVQUEzYb1xwSJUJlyZMKImz/ZVbpUmM9P4bRt24LqNMRE2Nn0l3KZS4FpMlk8RFh8XrEpZSDPP+y7c3t7840CHO9jV/qYDXQpaP4BvANgD4I7W9fcAvglgmeoXmLyqoKAldWYTq7eyrght4sKEETbhhq1yu7rmdqvZjpspA82mF/Pln+xgc0yoKuGqU58LsVMmKcLi44JVKQuq83zYAjTrOHBlMesyuvOgXQLgN1vXJao3LuIqu4KmmmJDd4ePyxHUaFR3Mi877RPuIfTLKXTJsFUuJ8p0uFJfqkq4ilLgyjOZpAhvQFk9Dqrtn+RWT9NnVNLW1H3hyDxollFdtaZZ4ei23oTtHGs0qj2Zlx1/wvWT0sb1G1pJ0+OClTSNEp72XlXsA4xBi0elTye5cHt71cdB0r2ESE4UXHWooFkkzarVpdiGMk9CdaLZlPKee7wNA0JE9zGX+hZRJ40SnkSWPlA2l2jZdnEWVb9pvkenC1clbU3efl12qKAVTHAwLFqkHsviUmwDBboeipyA41bGLvUtkg5VJTyJtH2grC7RIiyfOr7D1dQjSS7coSH1OU01bU2d5QwVNMMEhfDSpd5E2n4WokoHdCm2gQI9Py4JOJf6FslGXqVAtQ/489nAgKy9dcMkabwUeRZ6ab0hce/345JV5zTVtDVRcmbRIncXArqggmYAf8AMDUnZ3T23Ld+/2jv3OC5MVHRccitSoOfHpfZ0qSzEDip9IGxRUSXrhksuW1UvRd6FXlpvSNz3+cqZ6jySlLZmDKtjYytNH63mAlTQNKOyDfkOrJ43GB5GQyn3jCsWFwr0/NhwE0cJoOlpd/oWsYPK/BI27g+hP3FxWQaSnr/o3YSqXoq8c3EWb0iUtTZrHGNU2pqgnPTy+y2VD6Mhx3FhbeQNFTTNhA2YoAJ2BAtPmNTGcYHyisP2zjG/HGUQ6C6tiNvJ4ybO8lwqAsiFvkXskTS/hAngY+jMvHPUJXS67nSg6qXIu9DT6Q3JOqdFzU3t9zmE/spYa1WhgqaZsA5/HPOjd4MdLTgYTA98nQqLK8piFK4rkVknxqzPtX373PmctHqSLEQJ4EPot3akma75LEnRKToxsaplLG88sE5vSB5lLyhPurrC71MVa20aqKBpJmrA+Epa0Lfenphv0SJzio7rCotuXHfDZi1f1sOow87mrMsqtE6YtBonCeAi5xPd81mSolP02FF9vrwWMJ31qGvOjbpP0OVZZmttGqigaSZ8wJwkH0YjNOtyEZNasynlTTe5cTxNUbieCiTrxJjluXbs8D6zAMdquQqtC6YXYUlZ5AcHi7Oi616AqSifUcqbEGbCJ1S8FDrqQZc3RFf/i7qPTtnlcvhLECpoGmk2vZ2bUZ3J72g9PVIuWTLXMUxOanE7ZVxSWHRThlQgWSbGLM8VFD7H0Dn7mSl05W7/skx0LmC6rkxbjV2ywutegCUdO5SkvNmqB5faxC+PP6f193vpWAYH0/f39vuEpafK+oyu1VkcVNA0smOHd9RFlHLW1VV8rJZqrhkXFBadmE4FYksxyfJccbFDC3BMCpF9FVqWiS4vedu7iLoyYTVuf+6hIW/XXdSiIm6nsM7xonsBliV9RC9edsIb4WI8sO7+rvMZXQ9/CUIFTSNJE+TQkPEiKJXJz9ZcZT++yUFoUzHJ8lxJSt3ixXYmurJY33S0dxFCoUilJey5o97f26v/TEUTC7Bm0zuVYWDAW0x3dXnWn7vvDn8uW96IMowbl5Ug18NfglBB04iLbjWV8850KCyuTRgmVnBZjujSTZbnipsse3o8oZSFPBNdmaxvOoRNEUJBt9KiM8s8oHe8mFAA4vrkypXeOGk05o7Uiprn+/vTf7eOMro0blxWglyU01FQQdOIabeaiTLlzcZsc8JIUgxNB7+mmXxspjgx1UZ5JjqXV9jt6BA2RQiFIgLn45476f26Xa+6+7Rq/ZmySOssYx50zFUuK0EuyukoqKBpJM/gMWWFSgp+HR3N9x22BG2RimHUM6oc0VV0WaMwEaeSZ6JzeYXdjg5hU4RQKDr1RPtzJ71ft7DW3adV++SOHXM5BcewWh5CvzyEfnkHVs9apU3Ne6bHja4+5LISVKbFIRU0jWTt3CYFuGnlwJagLXKQRT2jyhFdRZe1SPI8l4sr7KhFkg5hU1Qf0Km0pH3upPe7KKyDqPbJZtNeXkHT48Z0LjMX5jwXFsyqUEHTTJYJsojt8aZ2+dgStEUqhlHPqHpEV5msRUkElZilS7Nvf3dthZ1lF1/aXFNlEQo+LsegRZHHE5GmT6aZ93R6R0yPG11zlev93cWdr2FQQXOAMgtwW4K2SMUw6RmTJh8XrUVZiJp0s+T1c22FXcRZjGURCj4u7+LUUd520vRJ1XlPt6JietzonKvK1t9dhAqaA5RZgNsStEUqhklxfElHdLlmLcqKzrZ2bYWdtEgaGqqnsMmyISXs/dPT5utPR9oX1T6p+l2650cbISvBucrP5Wl7l35doILmAGUW4LYEbZGKYZErc5fRbektcoWd5GYq8yLJBi6m1tHRP1X7pOqcYMI7onN3ensb3nRTvJva9kIqruy2+58JqKA5QNkFuA1TtinFMGrg57EAuGYtykpZlRiV+i/zIsk07WNiaEiPy1c3RfdPlXnP1TGT1h3tkmwyvanOJcWPCpoDVEWAF41uxdD0wC+7i0yHEmNjAlRZAJV9kWSKqDHhmtCW0k0l28UySZkcc+kf59XVdWL5bcdHmxqrLsphZxQ0AJ8HcBjA44HXTgGwC8BTrZ+vbb0uAPwJgKcBfAfAUNL9XVbQpEwW4K5p9lWkDELaZj8oMsZHJ0lupt7efDtSq0xcm9sU2mndc7bGr6tziqrr1UULoKlNdS62lUsK2jsBDLUpaJsAfKL1+ycA/GHr9/cA+FpLUXs7gIeT7l9UHjQTwtNFzb6KuL6b1nY/KGssXpKQCV5ZdqRWmbgxYUto294tqqOstuduVcXLlAUwj6w0pTS6OP87o6B5ZcFAm4L2PQCvb/3+egDfa/3+3wCMhL0v6jKtoJmMibrpJntnP9YJF1eLQVxY4eVx1dqaAOOETN66TBI0qoLIVQt53Jiw5bZTdc8lBfkXVd+uhTc0m+GJdsPasOgzT1VkZValsYwbhVxX0H7W9v+ftn7+FYBfCrz+dQDDcfc2raCZ7MgdHW5p9q4KkywEnyUs3sKFeBEflVQQNtslWJdLl0o5MCDl4OBcWRYtsjMBmnLTJQma6Wk1QeSqlUVKs8ptWvz+1dubbz50ub6LIM1RVdPTXn36MkhHXeWVlVk+X9aNQmVV0P5HiILWCLnfjQDGAYyfeeaZJupvFhPWgfaO6N/XpmZfpckt6llMnuiQR4FKWuH19Ljn/gxeYQuNIibAuLLlURaTBMXoqJ1cWbpIst6316XJvhbWhlnbztX69jG9AE6SVf5h736d+wpxcBw3Gp7yZuL7TSjYZd0o5LqCVhoXpwnzaFhHnmndN0mwmRrkaTqx65a2pKNpdAoeHYpt0grPphs8rC7HsFregdVWjvxpp93NFGaFSassqmw+UBFELsa+RAln//JPVyjKbRfWv1TPwm3Hxfr2KWIBnCSr+vu995lSWHTIyrRuY5U2d9H44LqC9kdtmwQ2tX7/tbZNAo8k3du0gmbCPBrVkf2OFTVQTHY01cnNxc7eTtKzCKFP8KhMdkkKbdKJBiaFTlLZwuryGDrlFLpOKItOd0lWdAifJEEjhJogcjH2JamvjY4W217hY/Uk+TAaqdvOxfr2KcKKoyqrkubHgYFsi28brkTVNnctXtAZBQ3AvQAOAZgGcBDAhwGc2nJfPtX6eUrrvQLAZwA8A+C7SfFnsgAFTcfAaheCSav8jo5wwWZykKt29Lgy9PRIec892cugi6hnOYT+WWtPMIYqT3C3SvxYkkIbp/T66SFMCB0VZTuqLsPK4h8XY3MCLMKiqWqlczH2xTUrk8pOXNNB5mHo9hLorPeosm3friYfVBcgaevfhivRxTGmgjMKmunL9V2ccXEyaVexJidXXasvP87BJsEyHkPnbIVPoWu2nHFtmabNkya7RYviFVpfURwaCt+lpnsCCk7uixYlu0/Dvn8KnXKqVa/HIeTDaMz2XdtxPv4z5lktlzUGTUWpcM3KpKIMq7adrvpWGf9pFLhmU99GmriyrVwZ/r/2FDODg/F1XqZ8iC7Gl6lABU0jURP+9HTyIFWNhwKk7OyM78gmJ1fVjp5knRLC/qDYsWNOAT6E/hPqSqdgzWJtCSq0SROZztjAqAk0TuGPikHbiyF5HCL0M2VHxy7OZtOzaPhpD0wLLFXh6JrFQUeIQNo6yFume+5R/564HftZ6l2lbL6s6u8PT9Lc0+PJmiiZlMcAULQrsQwhN2FQQTNMngnxCBbKMaxO7SI0OblmeZ4o65RtId1sxucDSpqA0lgqkybMuJWzqtKlK6VDVFnHceEJZfMV/qj7umKBiSOPmypJ0MT9P85qvmSJN8Z1Cw5VRV6nlUmHC1CHMtx+v7wKQtL4f93r1Ouwvb7HcYF8GA05jgsz1buuuamz80TFLe3Y9vvA0JA3z/X2ej+L3jTmWnyZClTQDKPD4pR2lWLanKvS0ZOsU64I6e3b53ICtdeVzuDuJAETp1SrrlRV2yWpb0RN7nG75nxL0ODgXD451UVCmBDfvt27Go3wnGq6JnYVwW9qJ7IrsTimNvnotlrE9W8bdal6QoXK+E1ql6h446xlC85NSd89ODjX/wcGpOzuTje243YDu27Bsg0VNMOoTohRAjqLcuOCOTfJOpWkZBZFnBUjqdxpLZVZBYzp1C3t/TFqch/HBalcOb6CHicwo+q/s9O7wiZ1nX05KSt9o2FuHNkIxE+7qDAZoxfsA3mVYBt1GRV3eQj981yBKnWtEqOatz6i5iaVPhE2Tm1YBusGFTTD5N31eAdWZ1JuXDDnxlmnXBqU7XU1MKBWbp2r9jyKYhpU+mPS5N6uqMTtCktSrNTYTIUAACAASURBVOLqMCmnmo4+pGK5MNV/VYSybstdkbFlKkqTrsWkjU0N7X33EPpD08pE1XUwTYWOvHxxZcsTHxsVY9o+xsPaLOzefi7PqsWkmoAKmmFUJ8Soicp15SYOFyx5WdAZz5X2e9Moivfck97ykHcy7uiYUxx8hT9JEPf2Ri8S4j4bfC0qp1reYa3ipjJllUlqCxP54op0BaooTXnL41vfdCs4Kvjj33+0qOdME9ulq13SzE15wh6CYzzMAJCUfselcBcXoYJmmLS765J21riu3LTjgiUvC6rlNvl8WbbKJ/UP1d1wae6dx3oR91mVnGp5J3YVa6Epq0ySVcKEElXkokllMZDHNZnV7aaTZjM5HUW7op20O1JXu4TNTffcMxfbGYz3zJrnMGksxFnQXAt3cREqaIbJMyGWVbnJSppYFF27w0yhc/daWB/4wheyuY+TlL5gYP7g4PzA/Ki+l8dtpro5YipgQdM5sac9nUHnd0e1RRGnQhQxr6gsBvIo91ndbrpJimNsz1sYptCpWpzzkDT277knuk9kHeOMQcsHFbQCqJuilYWklAPbt5tzLdp8lqz3D9uAkcbyELayzlqnedxUtmPQ4vqSv0FA9bmyKOVhbaErWaltVMZpmhCQ7ds9t39Xl3eF7SZUcbvZeM4gpuPlovqh6gkCYWQd4y7u4nR9cR+EChoxQvsgGBqS8qabogdF0mq4pyc5T5crq7E0z5L1/r47R1cKkzx1mtdKbHMXp1+GsAXUsWPe7yqxYNPT4e9tz86uIgjyBvL7Y8R23im/LMGwjfZ0KTfdFN/vfJecr7SGXS4osmkW4SY3asSNxSVL8i3q8nqCwvpj0YYK1xf37VBBI9qJsyClWUkfa9uyrhqwarup0zxL3vvrSgKct07zWImjLHq+y6W/X93dqouolX9Hh/f909Pz3zs0NKc0x8UVmbZIumqxiDotobdXytNOi4+z9ONwF+CYHMNqeQj98hD65R1YPVtHLqbxMWHJSkLF7ZtVoW0fp8Fj57JYomxYsopM/aIDKmgklDwdNGoQ9OLl1LEoYYqCa+cEtpPmWXTeP88xWq7XadGkUZJ27JhLx/EwGvOOtgo7CcSkRdK1mB//WYJKlkqc1s6dJyoyh9A/W7fBBUkeRceUIDaxwUeFpIWWLstdXkuULUuWykLUJSsbFTRyAnk7aNQgCGaibx8UYZ8JUxR803jWicbkhOy7lcKCvHUqPUnPn+UgepU6dWVVWQRpLIrB9wYVCF9pLtIiGbdrzoaVWTVXWG/viX0qaU4IjiXXlIQ0Z2HqjEtOWmgJocdylzfMxFaYShGpX3RCBa2EmBaUeTto1CBon2TjBkVwIg8qCkJ4cSxZEoiampCj3EpJz5K1S8a1T9I5rVnu6QuUqB2HPT3qAfFlUfBULYrN5px1qP29xyEKP+bMtbxTqguv4NXb6y10hIh/lqBLP8vOx6RxlOdoMVthGCqLNx3zX9Lz9fbG15mr9RNlLLAVQkMFrWQUYX7N20GjBkHSWY5hrpAwF03IXK1UB0nxGYOD2RSGJLdSnGs3Cyb6QNI9VU4LiPt+l9wGcfhKpGri0xPdm3PK2cNoZD4JJCtxFjQb8VlxCqNfnrg+1e42nkKHfBkL58Wg9fScmE8y7mxX/7WkdBd5+mnRIQP+Mw8MzJ8/TVnuVBI8x9WZrZAK06lfdEMFrWQUYX7N00GbTW9nVpiFK0lRaTa9CSQYTBw2eUblrBodjZ9oVOIzdK0mw9xKab8jzuKUJyg/7vui7hledyfJh9FQ6oNlOPYrTIlMKu/8ejlpnnLWniqk/fMmLIq6YtB0lS2s37SfVxk3xj3rc+cJ9eq3T2en2ukecbuCw+a5vP3U5E7NdlQ2ZeleCIU/n/p8UGT9BFFZKNoqWxhU0EpGWutWlok2awdN2kGmOmk0m/G5oLJa9uKC6/MoDKpuJSHUFSnXLE5RzxgMiI/rg3nythVFlsSnKpaE9mvJEinvvrtYd7t/qaT90Nn3su4qVHGJDg56C7pgeVTz6gXLEDbPZemnwbl20SKz57imqePBQf27nsO+My7GOE2ZTS/Ykha3jEGzcFVFQUtj3co60WbtoHGfE0LKSy9Vt/jEKYlZTc9Rq/m8ZzyacCsVNUmoKvBhz9geEO+3Q1fXiTnuAL1520ygElejcpZo2MHyYYpS1HE/edvXF0DBvFMnn6x+dJzOvhdn3fEtWipjvL1eh4bCvy+uDaPaNSx9xzguTNVPVaxYphZYOmOmVOeDsOdNMy/bWoCqPJ9Li2MqaCUjjXUr6RibKJdg1g6qc6KIK3tW03PYPXUoDCZSGxQRqJqmnZNWzO1KSZTLQFfeNhNkce2rppQJc+/Hte/AQLQQyWIVT6N06e57URaLuLjGOJdo3FhKc7arn5Ym7Fnj4mXT1m9Hh9nErLpiptLO+367Zj2o3kSYhq7nK7psUVBBKwhdMR06J9qOjvig7rAOOj0d/RxZJoqoepmejl6RZl3Zh7l/dMQZJLmVsqy8ighUTdOXkuKz4o5iUsnbds899nd4ZnHtR036cQI/OAbj0iGE9aGocaFz8VRUkHSc1SnKXZd0CkdcG8YtENqfdRwXpJpjbO780xUzZcJz4kp8qZTlKWcQKmiGaDbnzo7r7PQm3KhJN40QSrMKiEt3kaVjJn23ykQRVMiWLo13u0xPn5i5utE48ft7e+e2R6scsj46OpcPKCwzefuuMNW60XmcSRGBqlniGf1n7OmZf6xR3D2SnmXRovQr92Afaj8+KKtil+e8Qb+fRqWG8N3o7cpOVJ1ElWF0NFsZ0yhdRQe4q4xxwJtHk46sSopBi7KYJ7mok+Zqmzv/dCkeWZXMvC5BE5tldD6fTaigGaDZlPLKK0/cNaRLc1c1v8bFRmXpmEkTQZLwiMqllaZeVCf0uMkhaaBmSfSqmzLs1t2504s3S7pHUr6pj30snyWv/err897TnlZBJU9b3tiTKHfucYjQXHgqgevtcXBZhIyu0AjVvpdH6AbHeH+/euyc/9m4/pFGIW53Tfreg7BFWFjKjqJ2JUYdoxV2LFkcOuYDFZdgmkW66jys0t9cSp+hChU0A+zYMZdSIGih2YuhQjX39ok2LlGsCkmKzdBQtlxawVxRaeslizBJGqj9/enq2QRFBKrqsJSoWk3TWl6j+kFYe4e5Vzs7s036eWNP4jZEtO8WDiujfyW5PtMKmbzu7DR9r6hdoKqLuEbDWwREpXlR6Ssqu2NNbfqIQnWxkmVxYUrJjCqzar0FPVNdXd41MODJnqT+VqRlWBdU0AwQtYputo0e05q7PxjCjh7K0jFVViBxAi5KEOcJ1M9iti7LQDUdqKrDUpLm8OGoZ8nrfjsWsRPX1hb+sJQiYZsoVq6cOxDer5MkS0zagGxfoP3CL5wYYhEnwPP0PZ3WX11uqTilMawd2p9VZSNQ1kVBVlQXK6qnixRhtY/6DpVFepRnSlXJYwyaw1eRClpcXiw/NUFRCoEfc6UjJ0+SYjM0FG9mjgsWj7pfEmnTjqhk27YxUIuKw2j/zryWDt1uwSSlIynnXLDtbcWaxCXlBeLzUsUJkd5eL1WN6lhOEmhLlkj5hS+kdwUnoTPWR6dbKo/SqRouMjiY7f5Zxn+axcqiRcntbMtqr7pIj/JM+bHDSf2tiOfTDRU0A0RZ0KbQqZxpWSe6OmaS8EiKBYsSxGNYHSrIhoeTy6Yq3FXcASpJPE1gc+LQYaXT4RZUXdmGtXcwl12w7ZMsvaYU4jztGfXZ3l4pTzst3U7hJIHW3Z0+flMFnUqVK9Zuk2ecZu0vKouVYCoRFeueaat92kV6sH2j5WrX7LwR1iZ+gnA/O4AL6TNUoYJmgKSJ0YQAThI4YcH1o6P6gqj9iT5OyKbN8q2ivKoK96Rs2729J05gaXaHZqXZjD4ay2XTu07SCChVt06cUE+KldQ1HrMKgrDPxm3AAaRcuPDE/pkk0IDofpfnsHCdSpUrbqk4C1pehTHrM0YtVoIJpINtbbMOffkU5aIPW6S3ly1OIfU/l2cnrotQQTNAkmuhp0eP5u53+qEhKbu756c98Cdf/7valbU8K/wwwaPi1ogLtM3qDlF9lqTyRQkqFUuFaju1K3p+TquwGMEiXXK6rUkq92t/T3DBEKfQTE97/2vv6+3jKy5gO2uqCpsk9d/gs/tW4KgdtkHrgso90/b7Ik4iKFrYmkhG7ZPVJRy1WHlOIZWI6fklaadm0lwbJruSFhzt90w6+7kMUEEzRLPpBWYODs7tNgk7Oy7P/VUOdg6b0JJclWkta1KquzWiBGwed4iKtULlzMSwCSyvkEljdcy7yzYLugWgyv2yfmeUgi+E95rfX6PSuWTZNWqDMAU36mzasISqYYufKAta1JjIm2JDd5+y7ZaKW1zmVRizuoSj6jnKklRUeomocsXJp54eT4kLMzT4dRuM7Qx6prbgNxMt6O2paopOgp0VKmglJfmw2pMi491UrElpJx9Vt4bKLh4TMSZJ5YuawPIK8aQjYNrLlNVtktUKptuFpHI/ExnL2xcWcRY5l/MhRQm3qJ3Y7ScUhLmKokIt/F2dYWMib793QanSjf9Mccmog16N9vdEjcc8LuFgPS9aNJeAO0wR0uFyViHtTs3ubm9RFXf0V1+f954wz9T8vjon96I2HuRVqIuEClpJCRvU7YdX+3+3T7BJAiqLsFYVulHKYZhgyRMH066wDAxE76yLS0OSV4iruKbavyNovVNRkuKEepiLO0350g4blftl/U5dCwtXAs/DSIqVbH+9/VDvYLB1lLvSv7q6ol37JpVXGzuWi0DFyhaWQPmmm/QskqLmAV8RL8qlHzVOoxQmIdQt20HPVNT86cu9Y/M2D0UbLFyGClpJiVKy/M7ZrqwFJ9gkAZVFWEe5LtuFpIqrEfBWSe0rJdVVT9REFXXPuA0OUXXU1aUmWNK6VifbFA6V500S6nF1l1Q+f/WvKkhVrFNZLVi6FhauBJ6HkVYJbe87UUKwoyP6yLmwK63yqqp0uRJTZoKsudIWLvTce1k8F+20Wy4HBjwLVdTcoLJTPi0qOzWn0CkPoX/euIty40fNCypGimOt79mL7EnibS4oqKCVlHAla26VEHR9tE+wSQI9ayxE+8ox7KiRJOXQzwwdZe3Ku7PTt8q1HwCf9tBm1Uk06XmjLBgdHZ6LTmUSCBfqaitGlfLpfN4oC5qKEqBrYeGykqCqMC9aFN534kIFktztixZlG3t5d+G6ohznJW6nZ1IC5fZ5J+0xTWnKFCyLSq5JHd8Z3Kl5CP2hudrSJmFOCvMJ1n3WZOi25woqaJooWstO6woJToBp41ySBGeaSVflvXndblk+H5aGxLesJSlseeKmwr4j7eBPsqbGPXuWfhSXmVx3DFpwXEUpJVkWFq7GSKksYBoNz02W9sgcVRdSWoGUN4+daYWhqLlZNVda2LOnHQs6Ldq6yWoAWLQonfIet1GufcPVy1iYKZzB9oKCCpoGbGjZUd8ZdbWXJW2upbjOmEYhUqmrvIf2+i6EvJNSsI78lAVplcak59WROFHF1B/17GmU9eDzLlwYvrpXiYeLUi7C+qhKH9d1lJkLqLir/boKHlGkcqi46rhKq7ymGf9JZejpUQthUFVUipyb4yxokwFFLMyak1R3WZ/DRrxlUixcVFmy5CcMbtwI9v1N0JMkXneMblqooGnAlpbdvoMnr7ss6ySQVqFKEgB5JpUdO+bq4WE0Mh2tlSbNgarSeM898w/4HRz0FBUdAiLJ1J/07GHtEfW8wczkUfEr7ZNmmJs0y/mHYS65PAuL9jK7ELieJkVBmIUlalw1m8nnfGadIrOfpXqS9BcTD6Mx265x7RVVP1GngBQ5N6vEoJ2oOMRnwffrzsTO56JkUxoDQB7LdrPpfYc/XnTs4rS949tpBQ3AWwA8Grh+DmA1gN8F8KPA6+9JupdJBc22lq2zDFkGiO5VWp5JxZQAyGOlMb2KjzP1Z52Qg/UYFChNQLku8woH1T4dZ2lbsiRZEbYdZxJWnryW2/b7rVw5Z2HQLazTjP+oBZTqM6WxMBad8y5pF2fcgiep7rI+h0t9u4iyNJueJTmuP/b25juDtUjrvNMK2rwvBzoBPAfgF1oK2ro0nzepoNnWsm2VwV+h6j58PM9AzutCyRPbl+WeulaxKlarNAeg33TTXJu2r0SPQyhNUHmFY5o+7VspFy8+cZdi0rPbjjOJQ8e4TurTPT35BGTamMI8IQhRfSrqqKAky3faXcpJBMdhMA9aUgB8Ut0l9YOurng3ryvxlkWUJZjQNq5OVazmtueGMilo7wbwL63fnVLQbGvZNsqgEh+UZ2WUdSAn1UNSEHKSUqEriW/wnqopO1TJ6yZotwJswlrlmLYgeZWLtH1a55mGJq0saVypOsZ10vMNDuZXStIsqPI8k0oKhzQ7A3WktlCpn6FWcaOUZN9SGlWOpDrzn6XRyL/zs+yo9EfV92zfPmeRC15F1XWZFLTPA/i4nFPQDgD4Tuv11yZ9vooxaD6+xaPIA7eTVuWDg3ZWaXnbQjXNQRrFRzX3my2XWpCo8/32Yih1PF9e5SLtkWRhMVYqilZR1mfdOyRVEzkX8XxpFgX6QhiS87/F7QyMUpj6+jxrrK6YRP+Q8Di3bHsMnUo85hhWhx5xFIwNdSW2smiS+mNSH4w6Lq7o+boUChqAbgAvAFjW+ntZy+XZAeB2AJ+P+NyNAMYBjJ955pkm6k9Kmd+3nmcQJcU9mOpERVkd0taN6soo6p5ZlIqkMkbdM8ot42Ki1Cxlzassx1lpu7pO3LHoX2kVkaKsz1nqI6oO0iRydsHCr/JMKnNV2qPionYGJu1SXrxYX6xU+JhKl9k+rM68+0XH2boUf+YaSfJrYEBNITY9X5dFQVsJ4G8j/jcA4PGkexSRBy2LWynvIEra6aaa7DQtRa3Ksx6qHbebLe6eSefBqeTiaS9j2rPp2rtqkatgndY+HQIiLrYsyiKRVhEpygKeJ9C7PTt8UoxNsM/E7fC2tSDQPV+m3RmYFJsWdaZllvrKk6cwrM58d2jY/YL3se3ZcRmVmL72sRo8OqqoTYBlUdDuA/ChwN+vD/y+BsB9Sfdw9SSBona66aaIVbmJCSaraTtKqVApY5RQUQ1+L2oVrLIDyo+XSxPTljcoOK2Cm7a/FFXHuhY1SWM+ymrUfpXVkhLsUyr538JQienSNaeGfVeWmM6w+6U90q/o7AKuktT+UUpwnnGbBecVNAC9AF4EsDjw2j0AvtuKQXsoqLBFXa4qaEXudNNJEaszExOMyj3TKBWqZQzeM2x1FpeWIK+bUNX6tmPHnGVmDKvlIfTLQ+iXd2D1bMyTjVV3VB3HHb6cVhEpYneZygYWlbZSiZOMs6r7cZQunJzQThZrcZa2U0nXoWtOzZunMOx+KrkeXcguYJO4vpQU2+lnJgiO1al5h6/Tgqb1clVBK3qnmy6KsDqYmGB03zPL/XQejZPkEsm7u649LseGQFfZuRfs84ODZhWtrOg69itpzIftXCyD5aRoa3HUdy1ZondODfuuPAvbpF2h/lFsrsUeFklSX5qelvLKK0+M4wS81/yxyBi0mitoJne66bawhH3WpNXBxASj+55ZNxWoCqI8CmXavpH0Xf396eomK+19MipVgoubLOKIa/cwgdAucH2S2jXPqRc2KTpmKmr+iotDjTuHVuW7dOQplNJTMIYivG+dndniaauESl+Ky5cWtWAyvXBohwqaZUztdCsqiNskWVIMJCmcuoVA1vupKrd5FMq01jcXVtxxOzfj3FEu9ds4oto9jfUyady60I5ZcCVmqtmMt67k7WO6FrZJCVnTxtO2l7HM6TlU+pJKLGcw1nFwcL7MKcIyTwXNMlGTbfBwaRMxGFK6v8snbYqBlSv1JCjUUcY8yoKuHXhprW8u9AfVo3yA5NxReShaQMW5cRfgmBRC/dxNF9oxCy7FTKlmo7eJ7nhan7g5beVKr25cV9xU+pJL/S0KKmgOoNv8nfRdvuDRcc6fadKkGOjpUT/iQ6drVuf94ixIaftEWkuKCxbVJKHT22s+tsxGPQSfO+ww7TTj0YV2zIJLlj9XrHlxmFIw4hT8zs70O2ZtoNKXXOpvUVBBcwjTK9886R5cIWnidGlSzWKFScprl2YHXtbEqDbP7XNhVWvDArVjh/eoC3Di2adZnj1NO7riznLJ8udCP0zClIKRNMemnU9s9C2VvuRSf4uCCppDmF61pc3CbbLKsg5clUSqLkyqWa0YOvtAGS0pJoRO2r5mw3rSbCbnoIv63rwbfVzpIy6VxVXriq7whziS5ljVcWGzPVW+26X+FgUVNIcwvWqLEjw6d8OpCIusA6PZDD9vMS7BpK1JNevqTHcfsG0RS4vuVW2Wvqaym9WEVSBL3FNeIeOaFcGV/upavUipN/whjiTl1OWY1qD8Wbo0ObDflf4WBRU0hzC9ajN9aLeqsMhzJqEf/5AnBq0IslphXF25F4XuVW2WvpbUBjrPacz77C6cROKKi1QnLlpXdIY/ZP2eNHNT0ZZoF9ssL1TQHCIprUSW/DtBkgRP2mN80pQ/KCyyDNykSaOnR20XZ1FktYS5uHIvGp2rWt19zfQiIO2z5xWCeS22eYSi64qdS9aVKO+BCYUnqk17erzd87ryKuoOOani3EkFzSLtE9TQkHeZyr9jugOrCossAzfp3oODc3EFLkyqWS1hVVwF2iRLX4trg7As86oHnptQRmyfRJInDyD7uRp+Xfl1VITCEzaPps2rVrQ3oAw7b9NCBc0SURNUd7eZwM+479Q1KaoKiywDtwy7qoLkUYZdUTKrQB5FOawNdCt8ecedLQUr7vtVhGIVrR2maK+rQ+gv/ExInzRzU9FtrMMa7JpFlwqaJdL4+XWuAkwKf1VhYSIuyLHmpYXAEXQLiSz90KSgsnkSiZTZhWIVrR2mCKurY+iUh9DvtFJb9ByYR0a4Ol9TQSuQoIaelCS2LJaiIKrCwkYwtA3qaAlzbRVa5KaDjg4pR0fVXD26lBEdz5enn2YVimWziNskqa6EcHfRV+QcmEdGuCpfqKAVRNREqpJrxmVLUZA0wiLtwHV1hUPmcLWNdAoJ/xn9A9zbr7BnNa2M2FwIZBVsqhuWbLuYXCCprvz426qTtPjLM/+4atGlglYQaZPEuqbJq2JSWNTRIlUmXF2F6qbZ9CxlqrGiZXPPpyGrUFQ9c9W2cu8CdRlXcaj2s6wywlWLLhW0gojS0MOSxJblvDNCgri6CjVBmmfVIWBdcx23l03Xgdx1VkKicNUyXSQ2MhC4sIiiglYQaZLErlzpbWmmpYiUCVdXoSZI86x5BWxVBXRQsUuKya2Scp+FunsPTC/+XLVSUkErCNWYizoNOlItXF2FmiDts+YRsK4KD53USbkn6SkijtPFRRAVtIKowyRL6k2d+niRz1oH13GdlHuSniL6h4tWSipoBeGqhk6ILurUx4t81jpYl+qk3JP01LV/UEErEBc1dEJ0Uqc+XtSz1sG6VCflnqSnrv0jjYImvPeXk+HhYTk+Pm67GIQQkoqdO4FVq4CpySncjtuwAnuwByuwARvR3deNbduAG26wXcr8zMwA990HbN4MHDwInHEGcMstwPXXAx0dtktXLDMzwL33Alu2AM8+CyxfDqxZA4yM1K8ufIrqHy7VvRBiQko5rPReKmiEEFIsMzPANdcAu3cDk5Nzr/f1AZddBjz4YH2EtkvC0xRsb3u4VvdpFDR2CUIIKZiODuDLXwa2bQMaDWDZMu/ntm31Eta+8Fy1CpiYAA4f9n6uWgVce633/ypw772egjA1OYVNWIe9aGAT1mFqcgq7dnlWJGKGMtc9LWiEEEKsUBdX7/Cwp3huwjqMYiv6cBSTWIitGMV6jKHRACjKzOBa3aexoHWZLgwhhBASxpYtnttpE26bFZ5nYT8AYP3kGDZvroaC9uyz3s8V2IM+HAUA9OEoVmAPAC/+ipihzHVfE0M6IYQQ1yiz8EzD8uXezz1YgUksBAC8goXYgxUAvOB4YoYy1z0VNHICMzOe62F42IuNGR72/q5KPAghxA3KLDzTsGaNF5S+ARuxFaMYxxA+g1FswEb09Xk7F4kZylz3jEEj83BtxwshpLrUJQaN86o9XKt77uIkmSnzjhdCSLkYGQEuvRTo7uvGeozhIkxgPcbQ3deNyy7z8mFVAe7atUeZ654WNDIP13a8EEKqDZPZkjrBXZwkM3UJ2iWEuEFHh+fGrIIrkxCdcH1C5lGXoF1CCCHEZWhBI/NYs8YL2t0wuREA5gXtur7jhRBCCKkKVNDIPEZGgPvvB3bv7sb6ybHZ1/0dL1UJ2iWEEEJchi5OMo8y73ghhBBCqoI1C5oQ4gCAlwE0ARyXUg4LIU4B8CUAAwAOAPh1KeVPbZWxrjBolxBCCLGLbXvICinlBYEtp58A8HUp5ZsAfL31NyGEEEJIrbCtoLWzEsAXWr9/AcBVFstCCCGEEGIFmwqaBPC3QogJIcSNrdeWSSkPAUDrZ3/7h4QQNwohxoUQ488//3yBxSWEEEIIKQabuzjfIaX8sRCiH8AuIcSTKh+SUm4DsA3wThIwWUBCCCGEEBtYs6BJKX/c+nkYwFcAvA3AT4QQrweA1s/DtspHCCGEEGILKwqaEKJPCHGy/zuAdwN4HMBDAD7QetsHAPyFjfIRQgghhNjElotzGYCvCCH8MnxRSvk/hRB7Afx3IcSHAfxvANdZKh8hhBBCiDWsKGhSyh8AOD/k9RcB/ErxJSKEEEIIcQfX0mwQQgghhNQeKmiEEEIIIY5BBY0QQgghxDGElOVNJSaEeB7A/yro614H4IWCvovEw7ZwB7aFG7Ad3IFt4QautsMvSCmXqryx1ApakQghxgNnhhKLsC3cgW3hBmwHd2BbuEEVf2NXXAAABvRJREFU2oEuTkIIIYQQx6CCRgghhBDiGFTQ1NlmuwBkFraFO7At3IDt4A5sCzcofTswBo0QQgghxDFoQSOEEEIIcQwqaAoIIS4XQnxPCPG0EOITtstTdYQQnxdCHBZCPB547RQhxC4hxFOtn69tvS6EEH/SapvvCCGG7JW8Wgghlgsh9ggh9gshnhBC/HbrdbZFwQghThJCPCKEeKzVFr/Xen1QCPFwqy2+JITobr3e0/r76db/B2yWv2oIITqFEN8WQvxV62+2gwWEEAeEEN8VQjwqhBhvvVaZ+YkKWgJCiE4AnwHwqwDOBjAihDjbbqkqz90ALm977RMAvi6lfBOAr7f+Brx2eVPruhHAXQWVsQ4cB7BWSnkWgLcDuLnV99kWxXMMwCVSyvMBXADgciHE2wH8IYAtrbb4KYAPt97/YQA/lVL+HwC2tN5H9PHbAPYH/mY72GOFlPKCQEqNysxPVNCSeRuAp6WUP5BSTgG4D8BKy2WqNFLKfwTwUtvLKwF8ofX7FwBcFXh9u/T4FoAlQojXF1PSaiOlPCSl3Nf6/WV4AukNYFsUTqtOj7T+XNC6JIBLADzQer29Lfw2egDArwghREHFrTRCiDMA/BqAP2v9LcB2cInKzE9U0JJ5A4BnA38fbL1GimWZlPIQ4CkOAPpbr7N9CqDlmrkQwMNgW1ih5VZ7FMBhALsAPAPgZ1LK4623BOt7ti1a//83AKcWW+LK8scA1gOYaf19KtgOtpAA/lYIMSGEuLH1WmXmpy7bBSgBYasdbn11B7aPYYQQrwHwIIDVUsqfxxgA2BYGkVI2AVwghFgC4CsAzgp7W+sn28IAQoj3AjgspZwQQrzLfznkrWyHYniHlPLHQoh+ALuEEE/GvLd0bUELWjIHASwP/H0GgB9bKkud+Ylvjm79PNx6ne1jECHEAnjK2U4p5ZdbL7MtLCKl/BmAv4cXF7hECOEvtIP1PdsWrf8vxolhAyQ97wBwpRDiALxwl0vgWdTYDhaQUv649fMw/v/27ibEqyqM4/j350skFUGlKwkxpMg0QZMEC4lwkVEghkKStIkWLSQiqBaG4KIEKXPRJiEsBYksCdICzV7BijSV3kAiWlgLoZDCTJ8W90wNk2mNMfOfme8Hhrlz7v2fe2YO3Hnuueeep7tpmc8ouj4ZoJ3fx8CM9pbORcAKYOcwt2ks2gmsaturgNf7ld/X3tC5Gfipb3hbF6bNlXkB+KKqNvTbZV8MsSST28gZSSYBt9PNCdwLLGuHDeyLvj5aBuwpF728YFX1WFVNrappdP8L9lTVvdgPQy7JJUku69sGFgOHGUXXJxeq/ReS3EF3lzQe2FxV64a5SaNakm3AIuAq4AdgDfAasB24GvgOuKeqjrcgYhPdW5+/APdX1SfD0e7RJslC4D3gEH/Nt3mcbh6afTGEksymm/A8nu7GentVrU0ynW4k5wrgM2BlVZ1McjGwhW7e4HFgRVUdHZ7Wj07tEecjVXWn/TD02t98R/txArC1qtYluZJRcn0yQJMkSeoxPuKUJEnqMQZokiRJPcYATZIkqccYoEmSJPUYAzRJkqQeY4AmaURJcjrJgSRHkhxM8nCScW3fvCQbh6ldHw7HeSWNTi6zIWlESXKiqi5t21OArcAHVbVmeFsmSf8fR9AkjVgtxcsDwENthfBFSd4ASPJkkheTvJXk2yRLkzyd5FCSXS2NFUnmJtnXEi7v7pcm5p0kTyXZn+TrJLe08pmt7ECSz5PMaOUn2vckWZ/kcDvX8la+qNX5SpIvk7yccyQ2lTS2GaBJGtHayuzjgCln2X0NsAS4G3gJ2FtVs4BfgSUtSHsOWFZVc4HNQP9MIROqaj6wmi6jBcCDwLNVNQeYR5fjr7+lwBzgRrqUTOv7gj66FeVXA9cD0+lyO0rS30w4/yGS1PP+aSTqzao6leQQXZqkXa38EDANuBa4AXi7DWaNB/rn5+tLEP9pOx7gI+CJJFOBV6vqmwHnXAhsq6rTdImb9wE3AT8D+6vqe4AkB1qd7//XX1bS6OcImqQRreXkOw38eJbdJwGq6gxwql+i6jN0N6gBjlTVnPY1q6oWD/x8q39Cq2srcBfdKNzuJLcNbNI5mnuy3/afdUrSQAZokkasJJOB54FNNbg3nr4CJidZ0OqbmGTmec45HThaVRuBncDsAYe8CyxPMr6171Zg/yDaJmkM8+5N0kgzqT0enAj8DmwBNgymoqr6LckyYGOSy+muic8AR87xseXAyiSngGPA2gH7dwALgINAAY9W1bEk1w2mjZLGJpfZkCRJ6jE+4pQkSeoxBmiSJEk9xgBNkiSpxxigSZIk9RgDNEmSpB5jgCZJktRjDNAkSZJ6jAGaJElSj/kD/+KfR0ALIGsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def numerical_gradient(fun,w,e):\n",
    "    # get dimensionality\n",
    "    d = len(w)\n",
    "    # initialize numerical derivative\n",
    "    dh = np.zeros(d)\n",
    "    # go through dimensions to compute directional derivative\n",
    "    for i in range(d):\n",
    "        # copy the weight vector\n",
    "        nw = w.copy()\n",
    "        # perturb dimension i\n",
    "        nw[i] += e\n",
    "        # compute loss\n",
    "        l1, temp = fun(nw)\n",
    "        # perturb dimension i again\n",
    "        nw[i] -= 2*e\n",
    "        # compute loss\n",
    "        l2, temp = fun(nw)\n",
    "        # the gradient is the slope of the loss\n",
    "        dh[i] = (l1 - l2) / (2*e)\n",
    "    return dh\n",
    "\n",
    "def check_grad(fun,w,e, plot=True):\n",
    "    # evaluate symbolic gradient from fun()\n",
    "    loss, dy = fun(w)\n",
    "    # estimate gradient numerically from fun()\n",
    "    dh = numerical_gradient(fun,w,e)\n",
    "    \n",
    "    ii = np.arange(len(dy))\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.scatter(ii, dh[ii], c='b', marker='o', s=60)\n",
    "        plt.scatter(ii, dy[ii], c='r', marker='.', s=50)\n",
    "        plt.xlabel('Dimension')\n",
    "        plt.ylabel('Gradient value')\n",
    "        plt.legend([\"numeric\",\"symbolic\"])\n",
    "    \n",
    "    # return the norm of the difference scaled by the norm of the sum\n",
    "    return np.linalg.norm(dh - dy) / np.linalg.norm(dh + dy)\n",
    "\n",
    "# set lmbda (λ) arbitrarily\n",
    "lmbda = 0.1\n",
    "# dimensionality of the input\n",
    "_, d = xTr.shape\n",
    "# evaluate loss on random vector\n",
    "w = np.random.rand(d)\n",
    "# the lambda function notation is an inline way to define a function with only a single argument.\n",
    "ratio = check_grad(lambda weight: ridge(weight,xTr,yTr,lmbda), w, 1e-05)\n",
    "print(\"The norm ratio is {}.\".format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ridge_selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: ridge_test1 ... ✔ Passed!\n",
      "Running Test: ridge_test2 ... ✔ Passed!\n",
      "Running Test: ridge_test3 ... ✔ Passed!\n",
      "Running Test: ridge_test4 ... ✔ Passed!\n"
     ]
    }
   ],
   "source": [
    "# These tests will check that your ridge function returns the same total loss and gradient as the correct implementation\n",
    "\n",
    "N = 50\n",
    "D = 5\n",
    "X = np.vstack((np.random.randn(50, 5), np.random.randn(50, 5) + 2))\n",
    "Y = np.hstack((np.ones(50), -np.ones(50)))\n",
    "XUnit = np.array([[-1,1],[-1,0],[0,-1],[-1,2],[1,-2],[1,-1],[1,0],[0,1],[1,-2],[-1,2]])\n",
    "YUnit = np.hstack((np.ones(5), -np.ones(5)))\n",
    "\n",
    "def ridge_test1():\n",
    "    w = np.ones(2)\n",
    "    [lss1,grd1] = ridge(w, XUnit, YUnit, 0.05)\n",
    "    [lss2,grd2] = ridge_grader(w, XUnit, YUnit, 0.05)\n",
    "    return (np.linalg.norm(lss1 - lss2) < 1e-5), (np.linalg.norm(grd1 - grd2) < 1e-5)\n",
    "\n",
    "# Check whether gradient is consistent with loss\n",
    "def ridge_test2():\n",
    "    w = np.random.rand(D)\n",
    "    ratio = check_grad(lambda weight: ridge(weight,X,Y,0.3), w, 1e-05, False)\n",
    "    return (ratio < 1e-8)\n",
    "\n",
    "# Check whether loss is correct\n",
    "def ridge_test3():\n",
    "    w = np.random.rand(D)\n",
    "    [lss1, grd1] = ridge(w, X, Y, 0.3)\n",
    "    [lss2, grd2] = ridge_grader(w, X, Y, 0.3)\n",
    "    return (np.linalg.norm(lss1 - lss2) < 1e-5)\n",
    "\n",
    "# Check whether gradient is correct\n",
    "def ridge_test4():\n",
    "    w = np.random.rand(D)\n",
    "    [lss1, grd1] = ridge(w, X, Y, 0.3)\n",
    "    [lss2, grd2] = ridge_grader(w, X, Y, 0.3)\n",
    "    return (np.linalg.norm(grd1 - grd2) < 1e-5)\n",
    "\n",
    "runtest(ridge_test1,'ridge_test1')\n",
    "runtest(ridge_test2,'ridge_test2')\n",
    "runtest(ridge_test3,'ridge_test3')\n",
    "runtest(ridge_test4,'ridge_test4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ridge_test1",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs ridge test1\n",
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "# naive unit testing using simply w, x and y data\n",
    "w = np.ones(2)\n",
    "[lss1,grd1] = ridge(w, XUnit, YUnit, 0.05)\n",
    "[lss2,grd2] = ridge_grader(w, XUnit, YUnit, 0.05)\n",
    "assert (np.linalg.norm(lss1 - lss2) < 1e-5), (np.linalg.norm(grd1 - grd2) < 1e-5)\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ridge_test4",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs ridge test2\n",
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "# Check whether gradient is consistent with loss\n",
    "w = np.random.rand(D)\n",
    "ratio = check_grad(lambda weight: ridge(weight,X,Y,0.3),w,1e-05, False)\n",
    "assert (ratio < 1e-8)\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ridge_test4",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs ridge test3\n",
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "# Check whether loss is correct\n",
    "w = np.random.rand(D)\n",
    "[lss1, grd1] = ridge(w, X, Y, 0.3)\n",
    "[lss2, grd2] = ridge_grader(w, X, Y, 0.3)\n",
    "assert (np.linalg.norm(lss1 - lss2) < 1e-5)\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ridge_test4",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs ridge test4\n",
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "# Check whether gradient is correct\n",
    "w = np.random.rand(D)\n",
    "[lss1, grd1] = ridge(w, X, Y, 0.3)\n",
    "[lss2, grd2] = ridge_grader(w, X, Y, 0.3)\n",
    "assert (np.linalg.norm(grd1 - grd2) < 1e-5)\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-23331122645c7df8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3>Part Two [Graded]</h3>\n",
    "\n",
    "<p>Implement the function <code>grad_descent</code> which performs adaptive gradient descent. \n",
    "Make sure to include the tolerance variable to stop early if the norm of the gradient is less than the tolerance value (you can use the function <code>np.linalg.norm(x)</code>). When the norm of the gradient is tiny it means that you have arrived at a minimum.</p>\n",
    "\n",
    "<p>\n",
    "The first parameter of <code>grad_descent</code> is a function which takes a weight vector and returns loss and gradient.\n",
    "</p>                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-grad_descent",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def grad_descent(func, w, alpha, maxiter, delta=1e-02):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    func    : function to minimize\n",
    "              (loss, gradient = func(w))\n",
    "    w       : d dimensional initial weight vector \n",
    "    alpha   : initial gradient descent stepsize (scalar)\n",
    "    maxiter : maximum amount of iterations (scalar)\n",
    "    delta   : if norm(gradient)<delta, it quits (scalar)\n",
    "    \n",
    "    OUTPUTS:\n",
    "     \n",
    "    w      : d dimensional final weight vector\n",
    "    losses : vector containing loss at each iteration\n",
    "    \"\"\"\n",
    "    \n",
    "    losses = np.zeros(maxiter)\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    for i in range(maxiter):\n",
    "        losses[i], grad = func(w)\n",
    "        w -= alpha * grad\n",
    "        if np.linalg.norm(grad) < delta: \n",
    "            losses = losses[:i+1]\n",
    "            break\n",
    "    ### END SOLUTION\n",
    "    return w, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-grad_descent_selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: grad_descent_test1 ... ✔ Passed!\n",
      "Running Test: grad_descent_test2 ... ✔ Passed!\n",
      "Running Test: grad_descent_test3 ... ✔ Passed!\n"
     ]
    }
   ],
   "source": [
    "# These tests will check that your implementation of gradient descent returns the same weight vectors as the correct implementation upon convergence (tests 1 and 2) and at each iteration (test 3)\n",
    "\n",
    "def grad_descent_test1():\n",
    "    w = np.random.rand(D)\n",
    "    w2 = np.copy(w)\n",
    "    eps = 1e-06\n",
    "    weight1, _ = grad_descent(lambda weight: ridge(weight,X,Y,0.3),w,0.001,1,eps)\n",
    "    weight2, _ = grad_descent_grader(lambda weight: ridge_grader(weight,X,Y,0.3),w2,0.001,1,eps)\n",
    "    return (np.linalg.norm(weight1 - weight2) < 1e-5)\n",
    "\n",
    "# Check the convergence of adagrad\n",
    "def grad_descent_test2():\n",
    "    w = np.random.rand(D)\n",
    "    w2 = np.copy(w)\n",
    "    eps = 1e-06\n",
    "    weight1, _ = grad_descent(lambda weight: ridge(weight,X,Y,0.3),w,0.001,100,eps)\n",
    "    weight2, _ = grad_descent_grader(lambda weight: ridge_grader(weight,X,Y,0.3),w2,0.001,100,eps)\n",
    "    return (np.linalg.norm(weight1 - weight2) < 1e-5)\n",
    "\n",
    "# Check various steps of adagrad\n",
    "def grad_descent_test3():\n",
    "    w = np.random.rand(D)\n",
    "    w2 = np.copy(w)\n",
    "    eps = 1e-06\n",
    "    for i in range(25,101,25):\n",
    "        weight1, _ = grad_descent(lambda weight: ridge(weight,X,Y,0.3),w,0.001,i,eps)\n",
    "        weight2, _ = grad_descent(lambda weight: ridge_grader(weight,X,Y,0.3),w2,0.001,i,eps)\n",
    "        if not (np.linalg.norm(weight1 - weight2) < 1e-5): return False\n",
    "    return True\n",
    "\n",
    "runtest(grad_descent_test1,'grad_descent_test1')\n",
    "runtest(grad_descent_test2,'grad_descent_test2')\n",
    "runtest(grad_descent_test3,'grad_descent_test3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-grad_descent_test1",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs grad_descent test1\n",
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "# Check whether the first step of adagrad is correct\n",
    "w = np.random.rand(D)\n",
    "w2 = np.copy(w)\n",
    "eps = 1e-06\n",
    "weight1, _ = grad_descent(lambda weight: ridge(weight,X,Y,0.3),w,0.001,1,eps)\n",
    "weight2, _ = grad_descent_grader(lambda weight: ridge_grader(weight,X,Y,0.3),w2,0.001,1,eps)\n",
    "assert (np.linalg.norm(weight1 - weight2) < 1e-5)\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-grad_descent_test3",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs grad_descent test2\n",
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "# Check the convergence of adagrad\n",
    "w = np.random.rand(D)\n",
    "w2 = np.copy(w)\n",
    "eps = 1e-06\n",
    "weight1, _ = grad_descent(lambda weight: ridge(weight,X,Y,0.3),w,0.001,100,eps)\n",
    "weight2, _ = grad_descent_grader(lambda weight: ridge_grader(weight,X,Y,0.3),w2,0.001,100,eps)\n",
    "assert (np.linalg.norm(weight1 - weight2) < 1e-5)\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-grad_descent_test3",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs grad_descent test3\n",
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "# Check various steps of adagrad\n",
    "w = np.random.rand(D)\n",
    "w2 = np.copy(w)\n",
    "eps = 1e-06\n",
    "for i in range(25,101,25):\n",
    "    weight1, _ = grad_descent(lambda weight: ridge(weight,X,Y,0.3),w,0.001,i,eps)\n",
    "    weight2, _ = grad_descent(lambda weight: ridge_grader(weight,X,Y,0.3),w2,0.001,i,eps)\n",
    "    if not (np.linalg.norm(weight1 - weight2) < 1e-5): False\n",
    "assert True\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eb5544bfc6932042",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Loss: 0.726336\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, d = xTr.shape\n",
    "lmbda = 5\n",
    "w, losses = grad_descent(lambda weight: ridge(weight, xTr, yTr, lmbda), np.random.rand(d), 0.005, 4000)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.semilogy(losses, c='r', linestyle='-')\n",
    "plt.xlabel(\"Gradient updates\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Gradient Descent Convergence\")\n",
    "print(\"Final Loss: %f\" % losses[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0bec2e6204d4eaf4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3>Part Three [Graded]</h3>\n",
    "\n",
    "<p>Now, write the function <code>linclassify</code>, which returns the predictions for a vector <code>w</code> and a data set <code>xTv</code>. (You can take it from a previous project.)</p>\n",
    "\n",
    "<p>After this, you can check your training and validation accuracy by running the cell below.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-linclassify",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy 88.50%\n",
      "Validation accuracy 88.90%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def linclassify(w,xTr):\n",
    "    ### BEGIN SOLUTION\n",
    "    return np.sign(xTr.dot(w))\n",
    "    ### END SOLUTION\n",
    "\n",
    "# evaluate training accuracy\n",
    "preds = linclassify(w,xTr)\n",
    "trainingacc = np.mean(preds==yTr)\n",
    "# evaluate testing accuracy\n",
    "preds = linclassify(w,xTv)\n",
    "validationacc = np.mean(preds==yTv)\n",
    "print(\"Training accuracy %2.2f%%\\nValidation accuracy %2.2f%%\\n\" % (trainingacc*100,validationacc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-linclassify_selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: linclassify_test ... ✔ Passed!\n"
     ]
    }
   ],
   "source": [
    "# This test will check that your implementation of linclassify() returns the same prediction vector for a given weight vector and input data vector as the correct implementation\n",
    "\n",
    "def linclassify_test():\n",
    "    w = np.random.rand(D)\n",
    "    xtoy = np.random.rand(N,D)\n",
    "    pred1 = linclassify(w, xtoy)\n",
    "    pred2 = linclassify_grader(w, xtoy)\n",
    "    return (np.linalg.norm(pred1 - pred2) < 1e-10)\n",
    "\n",
    "runtest(linclassify_test,'linclassify_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-linclassify_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs linclassify tests\n",
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "w = np.random.rand(D)\n",
    "xtoy = np.random.rand(N,D)\n",
    "pred1 = linclassify(w, xtoy)\n",
    "pred2 = linclassify_grader(w, xtoy)\n",
    "assert (np.linalg.norm(pred1 - pred2) < 1e-10)\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-45b68a6b60864f7f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3>Part Four [Graded]</h3>\n",
    "\n",
    "<p>Now implement the other loss function, <code>logistic</code>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-logistic",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def logistic(w,xTr,yTr, lmbda):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    w     : d   dimensional weight vector\n",
    "    xTr   : nxd dimensional matrix (each row is an input vector)\n",
    "    yTr   : n   dimensional vector (each entry is a label)\n",
    "    \n",
    "    OUTPUTS:\n",
    "    loss     : the total loss obtained with w on xTr and yTr (scalar)\n",
    "    gradient : d dimensional gradient at w\n",
    "    \"\"\"\n",
    "    n, d = xTr.shape\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    e = np.exp((xTr@w).flatten() * - yTr)\n",
    "    loss = np.sum(np.log(1+e)) / n + lmbda * w.dot(w)\n",
    "    grad = np.dot(e * -yTr/(1+e), xTr) / n + 2*lmbda * w\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return loss,grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-logistic_selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: logistic_test1 ... ✔ Passed!\n",
      "Running Test: logistic_test2 ... ✔ Passed!\n",
      "Running Test: logistic_test3 ... ✔ Passed!\n",
      "Running Test: logistic_test4 ... ✔ Passed!\n"
     ]
    }
   ],
   "source": [
    "# These tests will check that your implementation of `logistic` returns the same loss and gradient as the correct implementation for a few randomly generated datasets\n",
    "\n",
    "def logistic_test1():\n",
    "    w = np.ones(2)\n",
    "    [lss1,grd1] = logistic(w, XUnit, YUnit, 0.3)\n",
    "    [lss2,grd2] = logistic_grader(w, XUnit, YUnit, 0.3)\n",
    "    return (np.linalg.norm(lss1 - lss2) < 1e-5), (np.linalg.norm(grd1 - grd2) < 1e-5)\n",
    "\n",
    "# Check whether gradient is consistent with loss\n",
    "def logistic_test2():\n",
    "    w = np.random.rand(D)\n",
    "    ratio = check_grad(lambda weight: logistic(weight,X,Y, 0.3),w,1e-05, False)\n",
    "    return (ratio < 1e-8)\n",
    "\n",
    "# Check whether loss is correct\n",
    "def logistic_test3():\n",
    "    w = np.random.rand(D)\n",
    "    [lss1, grd1] = logistic(w, X, Y, 0.3)\n",
    "    [lss2, grd2] = logistic_grader(w, X, Y, 0.3)\n",
    "    return (np.linalg.norm(lss1 - lss2) < 1e-5)\n",
    "\n",
    "# Check whether gradient is correct\n",
    "def logistic_test4():\n",
    "    w = np.random.rand(D)\n",
    "    [lss1, grd1] = logistic(w, X, Y, 0.3)\n",
    "    [lss2, grd2] = logistic_grader(w, X, Y, 0.3)\n",
    "    return (np.linalg.norm(grd1 - grd2) < 1e-5)\n",
    "\n",
    "logistic_unit_pass_lss, logistic_unit_pass_grd = logistic_test1()\n",
    "\n",
    "runtest(logistic_test1,'logistic_test1')\n",
    "runtest(logistic_test2,'logistic_test2')\n",
    "runtest(logistic_test3,'logistic_test3')\n",
    "runtest(logistic_test4,'logistic_test4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-logistic_test1",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs logistic test1\n",
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "# naive unit testing using simply w, x and y data\n",
    "w = np.ones(2)\n",
    "[lss1,grd1] = logistic(w, XUnit, YUnit, 0.3)\n",
    "[lss2,grd2] = logistic_grader(w, XUnit, YUnit, 0.3)\n",
    "assert (np.linalg.norm(lss1 - lss2) < 1e-5), (np.linalg.norm(grd1 - grd2) < 1e-5)\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-logistic_test4",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs logistic test2\n",
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "# Check whether gradient is consistent with loss\n",
    "w = np.random.rand(D)\n",
    "ratio = check_grad(lambda weight: logistic(weight,X,Y, 0.3),w,1e-05, False)\n",
    "assert (ratio < 1e-8)\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-logistic_test4",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs logistic test3\n",
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "# Check whether loss is correct\n",
    "w = np.random.rand(D)\n",
    "[lss1, grd1] = logistic(w, X, Y, 0.3)\n",
    "[lss2, grd2] = logistic_grader(w, X, Y, 0.3)\n",
    "assert (np.linalg.norm(lss1 - lss2) < 1e-5)\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-logistic_test4",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs logistic test4\n",
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "# Check whether gradient is correct\n",
    "w = np.random.rand(D)\n",
    "[lss1, grd1] = logistic(w, X, Y, 0.3)\n",
    "[lss2, grd2] = logistic_grader(w, X, Y, 0.3)\n",
    "assert (np.linalg.norm(grd1 - grd2) < 1e-5)\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-128295826d3a4770",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3>Test Your Loss Function</h3>\n",
    "\n",
    "<p>You can use the two cells below to test how well this loss function performs.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-920fdbab8d0e5152",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Gradient sanity check\n",
    "_, d = xTr.shape\n",
    "w = np.random.rand(d)\n",
    "ratio = check_grad(lambda weight: logistic(weight,xTr,yTr, lmbda),w,1e-05)\n",
    "print(\"The norm ratio is {}\".format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7ce62b0d3e9a2fb8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "lmbda = 0.5\n",
    "w, losses = grad_descent(lambda weight: logistic(weight, xTr, yTr, lmbda), np.random.rand(d), 0.001, 4000)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.semilogy(losses, c='r', linestyle='-')\n",
    "plt.xlabel(\"Gradient updates\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Gradient Descent Convergence\")\n",
    "print(\"Final Loss: %f\" % losses[-1])\n",
    "\n",
    "# evaluate training accuracy\n",
    "preds = linclassify(w,xTr)\n",
    "trainingacc = np.mean(preds==yTr)\n",
    "# evaluate testing accuracy\n",
    "preds = linclassify(w,xTv)\n",
    "validationacc = np.mean(preds==yTv)\n",
    "print(\"Training accuracy %2.2f%%\\nValidation accuracy %2.2f%%\\n\" % (trainingacc*100,validationacc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-81ac7561e7957cd8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h2>Challenge: Improve Your Spam Classifier <b>[Ungraded]</b></h2>\n",
    "\n",
    "<p>You can improve your classifier in two ways:</p>\n",
    "\n",
    "<ol>\n",
    "<li><b>Feature Extraction</b>:\n",
    "Modify the function <code>extract_features_comp()</code>.\n",
    "This function takes in a file path <code>path</code> and\n",
    "a feature dimension <code>B</code> and should output a feature vector of dimension <code>B</code>.\n",
    "The autograder will pass in a file path pointing to a file that contains an email,\n",
    "and set <code>B</code> = <code>feature_dimension</code>.\n",
    "We provide a naive feature extraction as an example.\n",
    "</li>\n",
    "<li><b>Model Training</b>:\n",
    "Modify the function <code>train_spam_filter_comp()</code>.\n",
    "This function takes in training data <code>xTr</code> and training labels <code>yTr</code> and\n",
    "should output a weight vector <code>w</code> for linear classification.\n",
    "We provide an initial implementation using gradient descent and ridge regression.\n",
    "</li>\n",
    "</ol>\n",
    "\n",
    "<p>Your model will be trained on the same training set above (loaded by <code>load_spam_data()</code>), but we will test its accuracy on a secret dataset of emails.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-extract_features_comp",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "feature_dimension = 512\n",
    "def extract_features_comp(path, B=feature_dimension):\n",
    "    '''\n",
    "    INPUT:\n",
    "    path : file path of email\n",
    "    B    : dimensionality of feature vector\n",
    "    \n",
    "    OUTPUTS:\n",
    "    x    : B dimensional vector\n",
    "    '''\n",
    "    x = np.zeros(B)\n",
    "    with open(path, 'r') as email_file:\n",
    "        email = email_file.read()\n",
    "        # breaks for non-ascii characters\n",
    "        tokens = email.split()\n",
    "        for token in tokens:\n",
    "            x[hash(token) % B] = 1\n",
    "    ### BEGIN SOLUTION\n",
    "    ### END SOLUTION\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-train_spam_filter_comp",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def train_spam_filter_comp(xTr, yTr):\n",
    "    '''\n",
    "    INPUT:\n",
    "    xTr : nxd dimensional matrix (each row is an input vector)\n",
    "    yTr : d   dimensional vector (each entry is a label)\n",
    "    \n",
    "    OUTPUTS:\n",
    "    w : d dimensional vector for linear classification\n",
    "    '''\n",
    "    n, d = xTr.shape\n",
    "    lmbda = 5\n",
    "    \n",
    "    w, losses = grad_descent(lambda weight: ridge(weight, xTr, yTr, lmbda), np.random.rand(d), 0.001, 1000)\n",
    "    ### BEGIN SOLUTION\n",
    "    ### END SOLUTION\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-comptest",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Competition test cell - no point value\n",
    "### BEGIN HIDDEN TESTS\n",
    "def competition_test():\n",
    "    xTr,yTr = load_spam_data(extract_features_comp, feature_dimension, 'data_train')\n",
    "    weight = train_spam_filter_comp(xTr, yTr)\n",
    "    xTe,yTe = load_spam_data(extract_features_comp, feature_dimension, 'data_test')\n",
    "    preds = linclassify_grader(weight, xTe)\n",
    "    pos_ind = (yTe == 1)\n",
    "    neg_ind = (yTe == -1)\n",
    "    pos_acc = np.mean(yTe[pos_ind] == preds[pos_ind])\n",
    "    neg_acc = np.mean(yTe[neg_ind] == preds[neg_ind])\n",
    "    test_accuracy = 0.5*pos_acc + 0.5*neg_acc\n",
    "    return analyze_grader(\"acc\", yTr, linclassify_grader(weight, xTr)), test_accuracy\n",
    "\n",
    "training_acc, test_acc = competition_test()\n",
    "print(\"Your features achieved training accuracy: {:.2f}% and test accuracy: {:.2f}%\".format(training_acc*100, test_acc*100))\n",
    "### END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
