{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-adcd3e653f734bce",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h2>About this Project</h2>\n",
    "<p>In this project, you will implement a regression tree that predicts the severity of a patient's heart disease based on a set of attributes. The training data is in <code>heart_disease_train.csv</code> and the test data is in <code>heart_disease_test.csv</code>. Before you begin, take a look at the two csv files and  <code>attribute.txt</code>, which contains a description of each attribute in the csv files.</p>\n",
    "\n",
    "<h3>Evaluation</h3>\n",
    "\n",
    "<p><strong>This project must be successfully completed and submitted in order to receive credit for this course. Your score on this project will be included in your final grade calculation.</strong><p>\n",
    "    \n",
    "<p>You are expected to write code where you see <em># YOUR CODE HERE</em> within the cells of this notebook. Not all cells will be graded; code input cells followed by cells marked with <em>#Autograder test cell</em> will be graded. Upon submitting your work, the code you write at these designated positions will be assessed using an \"autograder\" that will run all test cells to assess your code. You will receive feedback from the autograder that will identify any errors in your code. Use this feedback to improve your code if you need to resubmit. Be sure not to change the names of any provided functions, classes, or variables within the existing code cells, as this will interfere with the autograder. Also, remember to execute all code cells sequentially, not just those you’ve edited, to ensure your code runs properly.</p>\n",
    "    \n",
    "<p>You can resubmit your work as many times as necessary before the submission deadline. If you experience difficulty or have questions about this exercise, use the Q&A discussion board to engage with your peers or seek assistance from the instructor.<p>\n",
    "\n",
    "<p>Before starting your work, please review <a href=\"https://s3.amazonaws.com/ecornell/global/eCornellPlagiarismPolicy.pdf\">eCornell's policy regarding plagiarism</a> (the presentation of someone else's work as your own without source credit).</p>\n",
    "\n",
    "<h3>Submit Code for Autograder Feedback</h3>\n",
    "\n",
    "<p>Once you have completed your work on this notebook, you will submit your code for autograder review. Follow these steps:</p>\n",
    "\n",
    "<ol>\n",
    "  <li><strong>Save your notebook.</strong></li>\n",
    "  <li><strong>Mark as Completed —</strong> In the blue menu bar along the top of this code exercise window, you’ll see a menu item called <strong>Education</strong>. In the <strong>Education</strong> menu, click <strong>Mark as Completed</strong> to submit your code for autograder/instructor review. This process will take a moment and a progress bar will show you the status of your submission.</li>\n",
    "\t<li><strong>Review your results —</strong> Once your work is marked as complete, the results of the autograder will automatically be presented in a new tab within the code exercise window. You can click on the assessment name in this feedback window to see more details regarding specific feedback/errors in your code submission.</li>\n",
    "  <li><strong>Repeat, if necessary —</strong> The Jupyter notebook will always remain accessible in the first tabbed window of the exercise. To reattempt the work, you will first need to click <strong>Mark as Uncompleted</strong> in the <strong>Education</strong> menu and then proceed to make edits to the notebook. Once you are ready to resubmit, follow steps one through three. You can repeat this procedure as many times as necessary.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a388de7633cd305a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e9e10d01c7b253bf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running python 3.7.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('/home/codio/workspace/.guides/hf')\n",
    "from helper import *\n",
    "\n",
    "print('You\\'re running python %s' % sys.version.split(' ')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-91646b69c3bc1e6f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Implement a Regression Tree\n",
    "\n",
    "### Part One [Graded]\n",
    "\n",
    "Now, implement a function called <code>load_data</code>, which will load the given <code>.csv</code> file and return <code>X, y</code> where <code>X</code> are the patients' attributes and <code>y</code> is the severity of the patients' heart disease. <b>The function should handle two explicit cases. If label=True it should output the training data X and the corresponding label vector y; if label=False it should output only the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-load_data",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def load_data(file='heart_disease_train.csv', label=True):\n",
    "    '''\n",
    "    Input:\n",
    "        file: filename of the dataset\n",
    "        label: a boolean to decide whether to return the labels or not\n",
    "    Returns:\n",
    "        X: patient attributes\n",
    "        y: label (only if label=True)\n",
    "    '''\n",
    "    X = None\n",
    "    y = None\n",
    "    ### BEGIN SOLUTION\n",
    "    with open(file) as f:\n",
    "        columns = f.readline().rstrip().split(',')\n",
    "        df = {i: [] for i in columns}\n",
    "        \n",
    "        for i in f.readlines():\n",
    "            for ind_j, j in enumerate(i.rstrip().split(',')):\n",
    "                df[columns[ind_j]].append(float(j))\n",
    "    \n",
    "    \n",
    "    if label:\n",
    "        y = np.array(df['label'])\n",
    "        columns.remove('label')\n",
    "        X = np.vstack([df[i] for i in columns]).T\n",
    "        return X, y\n",
    "    else:\n",
    "        X = np.vstack([df[i] for i in columns]).T\n",
    "        return X\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a4ad4015d5024026",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X, y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-load_data_selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: load_data_test1 ... ✔ Passed!\n",
      "Running Test: load_data_test2 ... ✔ Passed!\n",
      "Running Test: load_data_test3 ... ✔ Passed!\n",
      "Running Test: load_data_test4 (Testing for correct types) ... ✔ Passed!\n",
      "Running Test: load_data_test5 (Testing training data for correctness) ... ✔ Passed!\n",
      "Running Test: load_data_test6 (training and testing data dimensions should match) ... ✔ Passed!\n",
      "Running Test: load_data_test7 (Testing testing data for correctness) ... ✔ Passed!\n"
     ]
    }
   ],
   "source": [
    "# The following tests check that your load_data function reads in the correct number of rows, the correct number of unique values for y, and the same training data as the correct implementation\n",
    "\n",
    "Xtrain, ytrain = load_data()\n",
    "Xtrain_grader, ytrain_grader = load_data_grader()\n",
    "Xtest = load_data(file='heart_disease_test.csv', label=False)\n",
    "Xtest_grader = load_data_grader(file='heart_disease_test.csv', label=False)\n",
    "\n",
    "def load_data_test1():\n",
    "    return (len(Xtrain) == len(ytrain))\n",
    "\n",
    "def load_data_test2():\n",
    "    return (len(Xtrain) == len(Xtrain_grader))\n",
    "\n",
    "def load_data_test3():\n",
    "    y_unique = np.sort(np.unique(ytrain))\n",
    "    y_grader_unique = np.sort(np.unique(ytrain_grader))\n",
    "    \n",
    "    if len(y_unique) != len(y_grader_unique):\n",
    "        return False\n",
    "    else:\n",
    "        return np.linalg.norm(y_unique - y_grader_unique) < 1e-7\n",
    "    \n",
    "def load_data_test4():\n",
    "    return(type(Xtrain)==np.ndarray and type(ytrain)==np.ndarray and type(Xtest)==np.ndarray)\n",
    "\n",
    "def load_data_test5():\n",
    "    Xtrain.sort()\n",
    "    Xtrain_grader.sort()\n",
    "    return np.linalg.norm(Xtrain-Xtrain_grader)<1e-07\n",
    "\n",
    "def load_data_test6():\n",
    "    ntr,dtr=Xtrain.shape\n",
    "    nte,dte=Xtest.shape\n",
    "    return dtr==dte\n",
    "\n",
    "def load_data_test7():\n",
    "    Xtest.sort()\n",
    "    Xtest_grader.sort()\n",
    "    return np.linalg.norm(Xtest-Xtest_grader)<1e-07\n",
    "\n",
    "runtest(load_data_test1,'load_data_test1')\n",
    "runtest(load_data_test2,'load_data_test2')\n",
    "runtest(load_data_test3,'load_data_test3')\n",
    "runtest(load_data_test4,'load_data_test4 (Testing for correct types)')\n",
    "runtest(load_data_test5,'load_data_test5 (Testing training data for correctness)')\n",
    "runtest(load_data_test6,'load_data_test6 (training and testing data dimensions should match)')\n",
    "runtest(load_data_test7,'load_data_test7 (Testing testing data for correctness)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(Xtest-Xtest_grader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-load_data_test1",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs load_data test1\n",
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "assert (len(Xtrain) == len(ytrain))\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-load_data_test2",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs load_data test2\n",
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "assert (len(Xtrain) == len(Xtrain_grader))\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-load_data_test3",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs load_data test3\n",
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "y_unique = np.sort(np.unique(ytrain))\n",
    "y_grader_unique = np.sort(np.unique(ytrain_grader))\n",
    "\n",
    "if len(y_unique) != len(y_grader_unique):\n",
    "    assert False\n",
    "else:\n",
    "    assert np.linalg.norm(y_unique - y_grader_unique) < 1e-7\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-load_data_test4",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs load_data test4\n",
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "Xtrain_flatten = np.sort(Xtrain.flatten())\n",
    "Xtrain_grader_flatten = np.sort(Xtrain_grader.flatten())\n",
    "assert np.linalg.norm(Xtrain_flatten - Xtrain_grader_flatten) < 1e-7\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-469361b5f1f5f4e5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now, you will use the regression tree from the previous assignment for this prediction problem. As a reminder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c90887080a238f11",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a regression with no restriction on its depth\n",
    "# if you want to create a tree of depth k\n",
    "# then call RegressionTree(depth=k)\n",
    "tree = RegressionTree(depth=np.inf)\n",
    "\n",
    "# To fit/train the regression tree\n",
    "tree.fit(X, y)\n",
    "\n",
    "# To use the trained regression tree to make predictions\n",
    "pred = tree.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e422aaa713e45c82",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part Two [Graded]\n",
    "\n",
    "In <code>test</code>, you will find the optimal regression tree for the dataset <code>heart_disease_train.csv</code> and return its prediction on <code>heart_disease_test.csv</code>. You will be evaluated based on <code>square_loss</code>. You will get a full score if the test loss on your classifier is less than 0.17. You may use any functions that you implemented in the previous project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-11c9465dc6096df3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def square_loss(pred, truth):\n",
    "    return np.mean((pred - truth)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-test",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    '''\n",
    "        prediction: the prediction of your classifier on the heart_disease_test.csv\n",
    "    '''\n",
    "    prediction = None\n",
    "    Xtrain, ytrain = load_data(file='heart_disease_train.csv', label=True)\n",
    "    ytrain=ytrain>0\n",
    "    Xtest = load_data(file='heart_disease_test.csv', label=False)\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    tree = RegressionTree(depth=4)\n",
    "    tree.fit(Xtrain, ytrain)\n",
    "    \n",
    "    prediction = tree.predict(Xtest)\n",
    "    ### END SOLUTION\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-test_selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your test loss: 0.1523\n",
      "Running Test: test_loss_test ... ✔ Passed!\n"
     ]
    }
   ],
   "source": [
    "# The following test wil check that your test function returns a loss less than 2 on a sample dataset\n",
    "# ground truth:\n",
    "gt = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "pred = test()\n",
    "test_loss = square_loss(pred, gt)\n",
    "print('Your test loss: {:0.4f}'.format(test_loss))\n",
    "\n",
    "def test_loss_test():\n",
    "    return (test_loss < 0.17)\n",
    "\n",
    "runtest(test_loss_test, 'test_loss_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.248206469010062"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_loss(np.mean(ytrain),gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain=(ytrain>0)*1.0\n",
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-test_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs test function test\n",
    "### BEGIN HIDDEN TESTS\n",
    "gt = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
    "       2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4])\n",
    "\n",
    "pred = test()\n",
    "test_loss = square_loss(pred, gt)\n",
    "assert (test_loss < 2.0)\n",
    "### END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
